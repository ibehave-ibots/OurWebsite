{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import dateutil.parser as parser\n",
    "from webdav4.fsspec import WebdavFileSystem\n",
    "from fsspec.implementations.local import LocalFileSystem\n",
    "from ibots_db.schema import ConsultingReport\n",
    "from ibots_db import update_all, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Setting parameters for papermill\n",
    "\n",
    "raw_dir = 'data/raw/'\n",
    "env_usr = 'REPORT_USR'\n",
    "env_pwd = 'REPORT_PWD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def process(reports_path: list):\n",
    "    consultants = []\n",
    "    \n",
    "    for report_path in reports_path:\n",
    "        consultants.append(extract_report_data(report_path))                \n",
    "    return consultants\n",
    "\n",
    "def extract_report_data(report_path):\n",
    "    document = Document(report_path)\n",
    "    report_data = reset_report_data()\n",
    "    reports = []\n",
    "    current_section = None\n",
    "\n",
    "    for para in document.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        \n",
    "        if text.startswith('Type:'):\n",
    "            if report_data['type']:\n",
    "                reports.append(report_data)\n",
    "                report_data = reset_report_data()\n",
    "            report_data['type'] = clean_text(text, 'Type:')\n",
    "            current_section = 'content'\n",
    "        elif text.startswith('Scholar:'):\n",
    "            report_data['scholar'] = clean_text(text, 'Scholar:')\n",
    "        elif text.startswith('Date:'):\n",
    "            report_data['date'] = clean_text(text, 'Date:')\n",
    "        elif text.startswith('Topic:'):\n",
    "            report_data['topic'] = clean_text(text, 'Topic:')\n",
    "        elif text.startswith('Content:'):\n",
    "            report_data['content'] = clean_text(text, 'Content:')\n",
    "            current_section = 'content'\n",
    "        elif current_section == 'content':\n",
    "            report_data['content'] += '\\n' + text\n",
    "\n",
    "    if report_data['type']:\n",
    "        reports.append(report_data)\n",
    "\n",
    "    return reports\n",
    "\n",
    "def clean_text(text, prefix):\n",
    "    return text.replace(prefix, '').strip()\n",
    "\n",
    "def reset_report_data():\n",
    "    return {'type': '', 'scholar': '', 'date': '', 'topic': '', 'content': ''}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download reports from sciebo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "USR = os.getenv(env_usr)\n",
    "PWD = os.getenv(env_pwd)\n",
    "fs = WebdavFileSystem(\"https://uni-bonn.sciebo.de/public.php/webdav\", auth=(USR, PWD))\n",
    "fs.download('/', raw_dir, recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fs_raw = LocalFileSystem()\n",
    "notebooks = fs_raw.ls(raw_dir, detail=False)\n",
    "notebooks = notebooks[1:] \n",
    "cons = process(reports_path=notebooks)\n",
    "cons\n",
    "consultant_names = [Path(notebook).stem for notebook in notebooks]\n",
    "\n",
    "to_dt = parser.parse\n",
    "reports = [entry | {'consultant': name, 'date': to_dt(entry['date'])} for name, con in zip(consultant_names, cons) for entry in con]\n",
    "\n",
    "entries = [ConsultingReport(**entry) for entry in reports]\n",
    "entries\n",
    "\n",
    "write_entry = {}\n",
    "for ind, entry in enumerate(entries):\n",
    "    key = entry.consultant + '_' + str(ind).zfill(3) + '_' + entry.date.strftime('%Y-%m-%d')\n",
    "    write_entry[key] = entry\n",
    "\n",
    "update_all(key='consulting_reports', data=write_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mohammad_000_2023-08-30': ConsultingReport(consultant='mohammad', content='Jens Tillmann is hosting a workshop next week with 20+ participants. The workshop has been allocated 1 hour 15 minutes, which makes accessibility of the tool and data an important and challenging aspect of the design. He would like to discuss and get some feedback on best practices and tips on how to prepare the software (A-SOiD) demo and example data.\\n\\nOutcomes: We discussed several aspects and potential ideas for making the workshop more accessible. For instance, using Gitpod environment to minimize time spent on setup. Furthermore, we also discussed ideas to make the content delivery more efficient and fun through discussions.\\n\\nNext steps: NA\\n\\nTimeline: Workshop design should be finalized within 2 to 3 days, as the event is quickly approaching.\\n\\nUsers: Jens Tillmann and the participants\\n\\nRelevant links:\\nGitHub repo for the workshop: https://github.com/JensBlack/A-SOID_workshop', date=datetime.datetime(2023, 8, 30, 0, 0), scholar='Jens Tillmann', topic='Feedback on workshop design', type='short'),\n",
       " 'mohammad_001_2023-08-31': ConsultingReport(consultant='mohammad', content='Initial chat about starting a club and how it could look like\\n\\nNext steps: Think of the design and come up with a proposal\\n\\nTimeline: The Meet-Up is planned to start early next year (i.e. 2024)\\n\\nUsers: Alana and Mohammad as main organizers, iBehave scholar as participants and contributors', date=datetime.datetime(2023, 8, 31, 0, 0), scholar='Alana Darcher', topic='ML Coding Meet-Up', type='short'),\n",
       " 'mohammad_002_2023-04-09': ConsultingReport(consultant='mohammad', content=\"Shan wants to fit models to electrophysiology data, specifically recording the heartbeat and neural responses in an anesthetized monkey. The primary goal of the modeling is to investigate neurons' tuning to the heartbeat phase, considering the circular nature of the data. We discussed challenges with the symmetry of the von Mises distribution and its limitation in capturing the asymmetric nature of the actual data distribution.\\n\\nNext steps: We planned two hands-on sessions where in the first session we‚Äôll look into the existing analysis implemented by Shan in Matlab and come up with a plan for next step(s) for the following hands-on session(s).\\n\\nTimeline: Unknown\\n\\nUsers: Shanqian Ma\", date=datetime.datetime(2023, 4, 9, 0, 0), scholar='Shanqian Ma', topic='Model fitting for periodic data', type='short'),\n",
       " 'mohammad_003_2023-05-09': ConsultingReport(consultant='mohammad', content='Philip and I discussed how he can make his application to the Neuroengineering master program in Munich stronger. We talked about the courses that he can take now to make his CV stronger, as well as potential internships and projects to expand his network.\\n\\nNext steps: NA\\n\\nTimeline: NA\\n\\nUsers: NA', date=datetime.datetime(2023, 5, 9, 0, 0), scholar='Philip Baxter A√ümann', topic='Neuroengineering master application', type='short'),\n",
       " 'mohammad_004_2023-09-13': ConsultingReport(consultant='mohammad', content='During this meeting we delved into the dataset, we looked at the code that Shan has implemented so far, using a Von Mises distribution, and the corresponding results. Additionally we discussed potential other distributions that might be easier to handle while capturing the asymmetric nature of the data. Finally, we created a GitHub repo where we both could access and place our code there as we work on this project.\\n\\nOutcomes: Better understanding of the data as well as project‚Äôs current state and implementation, a GitHub repo for version control, and more specific set of goals based on the current state:\\nFind alternative distributions that are more flexible than Von Mises\\nTweak the distribution such that it allows skewness accounting for the asymmetry in the data histogram\\n\\nNext steps:\\nLook into alternative distributions and implement them in Python\\n\\nTimeline: Unknown\\n\\nUsers: Shanqian Ma\\n\\nRelevant links:\\nGitHub repo: https://github.com/ShanqMa/heartCell_tuning', date=datetime.datetime(2023, 9, 13, 0, 0), scholar='Shanqian Ma', topic='Model fitting for periodic data', type='hands'),\n",
       " 'mohammad_005_2023-09-14': ConsultingReport(consultant='mohammad', content='We discussed the ideas for the design of the session, including aspects such as during, frequency, location, and different parts of a single session.\\n\\nNext steps: Finalize the proposal and contact/inform other parties:\\nDr. Nicholas Del Grosso as the iBOTS group leader\\nProf. Dominik Bach as the Chair for Artificial Intelligence and Neuroscience in Uni Bonn\\n\\nTimeline: The Meet-Up is planned to start early next year (i.e. 2024)\\n\\nUsers: Alana and Mohammad as main organizers, iBehave scholar as participants and contributors', date=datetime.datetime(2023, 9, 14, 0, 0), scholar='Alana Darcher', topic='ML Coding Meet-Up', type='short'),\n",
       " 'mohammad_006_2023-09-28': ConsultingReport(consultant='mohammad', content='During this meeting we talked about other potential distributions that could be used for modeling the data. After doing some research together, we decided to start with a Gaussian Mixture model (GMM) which allows capturing multimodal data distributions as well as skewness.\\n\\nOutcomes: We implemented a simple ‚ÄúMexican Hat‚Äù using the Pytorch package, which could be a good basis for more complex GMMs with more components.\\n\\nNext steps: While this session was our last hands-on session together, natural next steps would include:\\nBuilding on top of the current GMM implementation to allow variable number of Gaussian components\\nMaking the distribution compatible with circular/periodic data\\nDefining the objective function and fitting the model to the data\\n\\nTimeline: Unknown\\n\\nUsers: Shanqian Ma\\n\\nRelevant links:\\nGitHub repo: https://github.com/ShanqMa/heartCell_tuning', date=datetime.datetime(2023, 9, 28, 0, 0), scholar='Shanqian Ma', topic='Model fitting for periodic data', type='hands'),\n",
       " 'mohammad_007_2023-10-10': ConsultingReport(consultant='mohammad', content='Leon, from Prof. Tobias Rose‚Äôs research group, wants to set up the inception loop experiment with DataJoint integration. During this short we discussed the data he is using (calcium response from visual sensory neurons in mice to natural images) as well as the inception loop pipeline and its components. We planned a few initials to get started but since this project is a rather large project we kept the ending of our collaboration open. The general steps we planned to take over the next hands-on sessions were about:\\nTalking about ML concepts including deep neural networks, objective function, and different steps in model training pipeline\\nGetting started with Pytorch and implementing a simple but complete model training pipeline in Pytorch\\nUnderstanding the current state-of-the-art models based on deep neural networks (DNNs) for predicting neural responses to natural images\\nBuilding the current state-of-the-art models and reproducing existing results\\nIntegrating behavioral variables as additional predictors into the model\\nImplementing the pipeline for generating Most Exciting Inputs (MEIs)\\nApply the model and MEI pipeline on Leon‚Äôs data\\n\\nNext steps: Talking about ML concepts including deep neural networks, objective function, and different steps in model training pipeline\\n\\nTimeline: Not specific, but in general the sooner the better\\n\\nUsers: Leon Kremers\\n\\nRelevant links:\\nInception loops paper: https://www.nature.com/articles/s41593-019-0517-x', date=datetime.datetime(2023, 10, 10, 0, 0), scholar='Leon Kremers', topic='Building the Inception Loops pipeline', type='short'),\n",
       " 'mohammad_008_2023-12-10': ConsultingReport(consultant='mohammad', content='For this session we met in person and directly dived into the issue where the windows system could not recognize the GPUs even though Ginevra followed the installation instructions from DeepLapCut (DLC). We looked into the documentation again and importantly looked into the version of tensorflow, Cuda version, and the drivers for the GPUs.\\n\\nOutcomes: We made sure that drivers and versions are compatible by checking the tensorflow website as well as the Nvidia website. In the end we managed to make sure GPUs are recognizable and DLC can run on GPU.\\n\\nNext steps: NA\\n\\nTimeline: NA\\n\\nUsers: Ginevra Contini and colleagues', date=datetime.datetime(2023, 12, 10, 0, 0), scholar='Ginevra Contini', topic='DeepLabCut GPU access', type='short'),\n",
       " 'mohammad_009_2023-10-18': ConsultingReport(consultant='mohammad', content='During this session we covered the basic ML concepts that we need for the future sessions. This includes general model building and training pipeline, deep neural networks, objective function and likelihood, and (stochastic) gradient descent. We also created a GitHub repository so we can track and version control our progress. Additionally, we talked about the development environment both in terms of software (e.g. python packages such as Pytorch and VS Code as the IDE) and hardware (i.e. GPUs) we need.\\n\\nOutcomes: Understanding of essential ML concepts, setting the dev environment, and setting up the GitHub repository.\\n\\nNext steps: In the next session we‚Äôll be focusing getting started with Pytorch and general model building and training pipeline\\n\\nTimeline: Not specific, but in general the sooner the better\\n\\nUsers: Leon Kremers\\n\\nRelevant links:\\nGitHub repo: https://github.com/troselab/Inception-Loops', date=datetime.datetime(2023, 10, 18, 0, 0), scholar='Leon Kremers', topic='Inception Loop pipeline with a focus on ML concepts and setup', type='hands'),\n",
       " 'mohammad_010_2023-10-30': ConsultingReport(consultant='mohammad', content='Discussing the infrastructure for the Meet-Up including a website and GitHub organization\\n\\nNext steps: Create GitHub organization and build the website\\n\\nTimeline: The Meet-Up is planned to start early next year (i.e. 2024)\\n\\nUsers: Alana and Mohammad as main organizers, iBehave scholar as participants and contributors\\n\\nRelevant Links:\\nWebsite: https://mlcolearn.github.io/\\nGitHub organization: https://github.com/mlcolearn\\nSeries 1 repo: https://github.com/mlcolearn/mlcolearn-meetup-season1\\nAttendance: https://uni-bonn.sciebo.de/s/40Dp1X6rfDm7VPe', date=datetime.datetime(2023, 10, 30, 0, 0), scholar='Alana Darcher', topic='ML Coding Meet-Up', type='short'),\n",
       " 'mohammad_011_2023-02-11': ConsultingReport(consultant='mohammad', content='In this session we started with the implementation. To make sure we have a good understanding of the implementation and practical aspects of the concepts discussed in the previous session we implemented a simple, but complete, model building and training pipeline. This pipeline includes preparing the data and creating Pytorch dataloaders, building Pytorch models using the nn module, and training the model using stochastic gradient descent.\\n\\nOutcomes: We implemented the complete pipeline and managed to make it work (i.e. the model successfully trained) on a toy example.\\n\\nNext steps: Focus on the model building to create deep neural network models with Pytorch and explore different ways that these models can be created using the nn.Sequential module.\\n\\nTimeline: Not specific, but in general the sooner the better\\n\\nUsers: Leon Kremers\\n\\nRelevant links:\\nGitHub repo: https://github.com/troselab/Inception-Loops', date=datetime.datetime(2023, 2, 11, 0, 0), scholar='Leon Kremers', topic='Inception Loop pipeline with a focus on getting started with Pytorch and general model building and training pipeline', type='hands'),\n",
       " 'mohammad_012_2023-08-11': ConsultingReport(consultant='mohammad', content=\"We discussed the current behavior of DeepLabCut's multi-animal pose tracking which assigns the same color from the colormap to all points of an individual animal. While this provides a clear distinction between animals, it makes it very difficult to distinguish different body parts for a single animal. Furthermore, this does not correspond to the same behavior of the single-animal labeling where the colormap is applied to different points on the skeleton.\\n\\nNext steps: We planned on a single hands-on session to look into the GUI and config file and see if we can resolve the issue together.\\n\\nTimeline: Unknown\\n\\nUsers: Ginevra Contini\", date=datetime.datetime(2023, 8, 11, 0, 0), scholar='Ginevra Contini', topic='Tracking multiple animals with DLC', type='short'),\n",
       " 'mohammad_013_2023-11-20': ConsultingReport(consultant='mohammad', content='Building on top of our progress from the last meeting we continued with the model building and training pipeline. During this session we focused on model building to learn how we can build deep neural networks (DNNs) in Pytorch, what should be considered to make them applicable to neural responses, and explored different ways that these models can be created.\\n\\nOutcomes: We cleared some doubts from the last session, and learned different ways to create deep neural network models using the nn.Sequential module\\n\\nNext steps: Understanding the architecture of the state-of-the-art DNN-based models for predicting neural responses to natural images. Specifically we will be looking at the models from the Sensorium 2022 competition.\\n\\nTimeline: Not specific, but in general the sooner the better\\n\\nUsers: Leon Kremers\\n\\nRelevant links:\\nGitHub repo: https://github.com/troselab/Inception-Loops\\nSensorium repo: https://github.com/sinzlab/sensorium', date=datetime.datetime(2023, 11, 20, 0, 0), scholar='Leon Kremers', topic='Inception Loop pipeline with a focus on model building and training pipeline', type='hands'),\n",
       " 'mohammad_014_2023-11-21': ConsultingReport(consultant='mohammad', content='Despite following the documentation and examples, and trying different things we did not manage to make it work: DLC still does not distinguish between different body parts for a single animal using different colors, but rather uses different colors across animals.\\n\\nOutcomes: We opened an issue on the DLC GitHub repo.\\n\\nNext steps: Hopefully the DLC team will respond and we can resolve the issue with their help.\\n\\nTimeline: Unknown\\n\\nUsers: Ginevra Contini\\n\\nRelevant links:\\nIssue on GitHub: https://github.com/DeepLabCut/DeepLabCut/issues/2451', date=datetime.datetime(2023, 11, 21, 0, 0), scholar='Ginevra Contini', topic='Tracking multiple animals with DLC', type='hands'),\n",
       " 'mohammad_015_2023-04-12': ConsultingReport(consultant='mohammad', content='Anoushka has recorded neural responses using multi-electrode recordings and wants to automate the processing steps of looking at the data and manually labeling them as noise, single-unit, or multi-unit activity. She has tried multiple classification methods from the scikit-learn Python package. However, the issue is that she cannot reproduce some of her older results which showed good classification accuracy and at the moment the classification accuracy is rather low.\\n\\nOutcomes: Mohammad got a good understanding of the problem at hand; we created a GitHub repo to version control our progress while working together, and agreed on action items for the next hands-on session.\\n\\nNext steps: We decided to start from scratch and implement a complete classification pipeline together and compare the results with Anoushka‚Äôs results.\\n\\nTimeline: Unknown\\n\\nUsers: Anoushka Jain and potentially collaborators/users of the SpikeInterface Python package\\n\\nRelevant Links:\\nAnoushka‚Äôs GitHub repo: https://github.com/anoushkajain/neuronID_study\\nSpikeInterface GitHub repo: https://github.com/SpikeInterface/spikeinterface', date=datetime.datetime(2023, 4, 12, 0, 0), scholar='Anoushka Jain', topic='Automated classification of multi-unit vs single-unit activity', type='hands'),\n",
       " 'mohammad_016_2023-06-12': ConsultingReport(consultant='mohammad', content='Therese is working on a project called fUSI where they have some code for the visualization of brain activity, I believe fMRI, across the brain. She would like to create the equivalent Python code that creates the same figures as the ones generated via the Matlab code.\\n\\nNext steps: We planned two-three hands-on sessions to translate the Matlab code into Python code, generating the same figures.\\n\\nTimeline: Unknown\\n\\nUsers: Therese Alich', date=datetime.datetime(2023, 6, 12, 0, 0), scholar='Therese Alich', topic='Converting Matlab code to Python code for the fUSI project', type='short'),\n",
       " 'mohammad_017_2023-11-12': ConsultingReport(consultant='mohammad', content='In this session we started working on the state-of-the-art DNN-based models that are used for predicting neural responses to natural images. In particular, we looked at the models from the Sensorium 2022 competition. These models are constructed mainly from two parts: Core and Readout. The Core extracts nonlinear global features from the input image and the readout fits a linear model on top of these features to predict the response of each neuron. In this session we focused on understanding and implementing the Core part of these models.\\n\\nOutcomes: We implemented the Core from scratch and got a good understanding of its architecture and different parts including the layers, nonlinearities, and regularization.\\n\\nNext steps: In the next session we‚Äôll be focusing on the other major part of these models, i.e. the Readout\\n\\nTimeline: Not specific, but in general the sooner the better\\n\\nUsers: Leon Kremers\\n\\nRelevant links:\\nGitHub repo: https://github.com/troselab/Inception-Loops\\nSensorium repo: https://github.com/sinzlab/sensorium', date=datetime.datetime(2023, 11, 12, 0, 0), scholar='Leon Kremers', topic='Inception Loop pipeline with a focus on state-of-the-art models, based on deep neural networks (DNNs), for predicting neural responses to natural images', type='hands'),\n",
       " 'mohammad_018_2023-12-13': ConsultingReport(consultant='mohammad', content='In this session we worked on building a complete classification pipeline from scratch. Our goal was to see what accuracy we achieve and whether the lower accuracy that Anoushka achieves now (compared to past results) is because of the data, model, or some bug in her code.\\n\\nOutcomes: We managed to get a good classification accuracy which was similar to what Anoushka achieved earlier (and she was expecting to achieve based on past results). We concluded that the current lower accuracy that Anoushka achieves is potentially due to a bug in the code.\\n\\nNext steps: Look into Anoushka‚Äôs code and fix the bug.\\n\\nTimeline: Unknown\\n\\nUsers: Anoushka Jain and potentially collaborators/users of the SpikeInterface Python package\\n\\nRelevant Links:\\nAnoushka‚Äôs GitHub repo: https://github.com/anoushkajain/neuronID_study\\nSpikeInterface GitHub repo: https://github.com/SpikeInterface/spikeinterface', date=datetime.datetime(2023, 12, 13, 0, 0), scholar='Anoushka Jain', topic='Automated classification of multi-unit vs single-unit activity', type='hands'),\n",
       " 'mohammad_019_2023-12-14': ConsultingReport(consultant='mohammad', content='During this hands-on session we created a Github repo where we can version control out progress, and worked together on creating Figure 1 in Python.\\n\\nOutcomes: We finished the code which creates the Figure in Python and checked that the figure is the same as the one that the Matlab code generates.\\n\\nNext steps: Working on Figure 2.\\n\\nTimeline: Unknown\\n\\nUsers: Therese Alich\\n\\nRelevant links:\\nGitHub repo: https://github.com/tcalich/fUSI-python', date=datetime.datetime(2023, 12, 14, 0, 0), scholar='Therese Alich', topic='Converting Matlab code to Python code for the fUSI project', type='hands'),\n",
       " 'mohammad_020_2023-12-19': ConsultingReport(consultant='mohammad', content='During this hands-on session we worked together on creating Figure 2 in Python.\\n\\nOutcomes: We finished the code which creates Figure 2 in Python and checked that the figure is the same as the one that the Matlab code generates.\\n\\nNext steps: Working on Figure 3.\\n\\nTimeline: Unknown\\n\\nUsers: Therese Alich\\n\\nRelevant links:\\nGitHub repo: https://github.com/tcalich/fUSI-python', date=datetime.datetime(2023, 12, 19, 0, 0), scholar='Therese Alich', topic='Converting Matlab code to Python code for the fUSI project', type='hands'),\n",
       " 'mohammad_021_2023-12-21': ConsultingReport(consultant='mohammad', content='For this meeting we planned to look into Anoushka‚Äôs code and find the bug which gives rise to unexpectedly low classification accuracy. However, this was a short meeting since Anoushka already looked into this, fixed the issue, and everything seems to work as expected.\\n\\nOutcomes: Anoushka‚Äôs approach achieves classification accuracy she expects from past results.\\n\\nNext steps: NA\\n\\nTimeline: Unknown\\n\\nUsers: Anoushka Jain and potentially collaborators/users of the SpikeInterface Python package\\n\\nRelevant Links:\\nAnoushka‚Äôs GitHub repo: https://github.com/anoushkajain/neuronID_study\\nSpikeInterface GitHub repo: https://github.com/SpikeInterface/spikeinterface', date=datetime.datetime(2023, 12, 21, 0, 0), scholar='Anoushka Jain', topic='Automated classification of multi-unit vs single-unit activity', type='hands'),\n",
       " 'mohammad_022_2023-12-21': ConsultingReport(consultant='mohammad', content='In this session we continued working on the state-of-the-art DNN-based models that are used for predicting neural responses to natural images. In particular, we looked at the models from the Sensorium 2022 competition. These models are constructed mainly from two parts: Core and Readout. The Core extracts nonlinear global features from the input image and the readout fits a linear model on top of these features to predict the response of each neuron. While in the last session we focused on the Core part, in this session we focused on understanding the Readout part and integrating it with the core to build a complete model for predicting neural responses.\\n\\nOutcomes: Understood the general idea behind the readout (e.g. how does the Gaussian readout works), integrated the readout with the core to create a complete model for predicting neural responses, and to make sure the model works we successfully reproduced results from the Sensorium competition by training the model on their public dataset.\\n\\nNext steps: In the next session we will build on top of the current model to include behavioral variables as predictors in addition to the sensory stimulus (i.e. image)\\n\\nTimeline: Not specific, but in general the sooner the better\\n\\nUsers: Leon Kremers\\n\\nRelevant links:\\nGitHub repo: https://github.com/troselab/Inception-Loops\\nSensorium repo: https://github.com/sinzlab/sensorium', date=datetime.datetime(2023, 12, 21, 0, 0), scholar='Leon Kremers', topic='Inception Loop pipeline with a focus on state-of-the-art models, based on deep neural networks, for predicting neural responses to natural images', type='hands'),\n",
       " 'mohammad_023_2024-04-01': ConsultingReport(consultant='mohammad', content='Karen is using a number of Python scripts to preprocess her Calcium Imaging data. However, as the preprocessing scripts are running she gets a system failure error, which consequently interrupts the whole preprocessing pipeline.\\n\\nNext steps: We decided to meet in person and dive deeper into the problem together.\\n\\nTimeline: As soon as possible since the pipeline is important for the whole research group.\\n\\nUsers: Karen Cheng and colleagues', date=datetime.datetime(2024, 4, 1, 0, 0), scholar='Karen Cheng', topic='Ubuntu 14 system failure during the preprocessing of Calcium Imaging data', type='short'),\n",
       " 'mohammad_024_2024-08-01': ConsultingReport(consultant='mohammad', content='In this session we continued working on the state-of-the-art DNN-based models that are used for predicting neural responses to natural images. We used the models from the Sensorium 2022 competition where they had two main tracks: Sensorium and Sensorium+. The Sensorium+ track contains models that use additional predictors (on top of the stimulus) to obtain better predictive models. Behavioral variables recorded during the experimental session are a common choice of additional predictors and have been shown to yield significant predictive power. Since Leon also has behavioral variables in his dataset having such models are quite relevant for his research. Therefore, in this session we focused on including behavioral variables as additional predictors to the model.\\n\\nOutcomes: Discussed and understood different ways that behavioral variables can be included as predictors and how it is done in the Sensorium+ base model, implemented the addition of behavioral variables as predictors, and reproduced the results from Sensorium+.\\n\\nNext steps: With this session we concluded our exploration of the models for predicting neural responses to natural images. In the next session we will continue with the other essential component of the Inception Loop pipeline: Most Exciting Images (MEIs).\\n\\nTimeline: Not specific, but in general the sooner the better\\n\\nUsers: Leon Kremers\\n\\nRelevant links:\\nGitHub repo: https://github.com/troselab/Inception-Loops\\nSensorium repo: https://github.com/sinzlab/sensorium', date=datetime.datetime(2024, 8, 1, 0, 0), scholar='Leon Kremers', topic='Inception Loop pipeline with a focus on including behavioral variables as additional predictors to the model', type='hands'),\n",
       " 'mohammad_025_2024-11-01': ConsultingReport(consultant='mohammad', content='We looked into the Python script that was resulting in the error. By using the Python debugger we managed to isolate the lines of code that were resulting in the error which turned out to be related to saving the data.\\n\\nOutcomes: By fixing the data saving issue we managed to run the first Python scripts successfully.\\n\\nNext steps: We agreed that Karen and Ogulcan will test the whole pipeline given the progress from today, and if they encounter problems that they need help with, they‚Äôll contact iBOTS.\\n\\nTimeline: As soon as possible since the pipeline is important for the whole research group.\\n\\nUsers: Karen Cheng and colleagues', date=datetime.datetime(2024, 11, 1, 0, 0), scholar='Karen Cheng and Ogulcan Cingiler', topic='Ubuntu 14 system failure during the preprocessing of Calcium Imaging data', type='hands'),\n",
       " 'mohammad_026_2024-01-15': ConsultingReport(consultant='mohammad', content='Inception loop pipeline contains the following steps: Train a model to predict neural responses, use the model to find Most Exciting Images (MEIs) for neurons, and finally show these MEIs to the subject and record the response of the biological neurons. In the past sessions we have already gone through building and training the models, and in this session we focused on using these models to find MEIs for the model neurons.\\n\\nOutcomes: We implemented the MEI pipeline and applied on the models we trained from previous sessions to produce MEIs.\\n\\nNext steps: With the MEI pipeline implemented, the next step is to prepare Leon‚Äôs data for model training and applying the MEI pipeline.\\n\\nTimeline: Not specific, but in general the sooner the better\\n\\nUsers: Leon Kremers\\n\\nRelevant links:\\nGitHub repo: https://github.com/troselab/Inception-Loops', date=datetime.datetime(2024, 1, 15, 0, 0), scholar='Leon Kremers', topic='Inception Loop pipeline with a focus on understanding and implementing the pipeline for generating Most Exciting Images (MEIs)', type='hands'),\n",
       " 'mohammad_027_2023-01-15': ConsultingReport(consultant='mohammad', content='Fabian is currently planning an automated application system for odors, e.g. predator urine, to study effects on mouse behavior. Mice will be exposed to the odor for several hours in a semi-naturalistic setup. At the moment he is building a prototype: It is based on an arduino controller that activates a magnet valve to apply odors. Simultaneously, it measures conductivity to monitor if there is still odor present, to re-apply odor when it is drying out. We discussed his idea for this application system and Mohammad suggested to him to discuss this further with the iBOTS:make team since they have more expertise with the hardware aspect of these setups..\\n\\nNext steps: Mohammad will connect Fabian with Ben from the iBOTS:make team.\\n\\nTimeline: A week or two as Fabian wants to start building the setup as soon as possible.\\n\\nUsers: Fabian Quicken', date=datetime.datetime(2023, 1, 15, 0, 0), scholar='Fabian Quicken', topic='Feedback on the design of the experimental setup', type='short'),\n",
       " 'mohammad_028_2024-01-18': ConsultingReport(consultant='mohammad', content='During this hands-on session we worked together on creating Figure 3 in Python.\\n\\nOutcomes: We finished the code which creates Figure 3 in Python and checked that the figure is the same as the one that the Matlab code generates.\\n\\nNext steps: Therese will work on the next figures on her own and in case she would like to work on them together, she will contact iBOTS again.\\n\\nTimeline: Unknown\\n\\nUsers: Therese Alich\\n\\nRelevant links:\\nGitHub repo: https://github.com/tcalich/fUSI-python', date=datetime.datetime(2024, 1, 18, 0, 0), scholar='Therese Alich', topic='Converting Matlab code to Python code for the fUSI project', type='hands'),\n",
       " 'mohammad_029_2024-01-22': ConsultingReport(consultant='mohammad', content='In this session we discussed and worked on preparing the data for model training. Specifically we talked about a format that can be easily used with the functions and methods we used in the past sessions. We applied the model on the exported data and did some investigation as to why the model does yield valid loss values.\\n\\nOutcomes: Data was exported and we applied the model on it. However, the model did not yield valid loss values which interrupts the training. We then looked into the exported data and did some checks to see what was potentially going wrong. For instance, making sure that the responses are positive-values, or if the train-validation-test split is done correctly.\\n\\nNext steps: We planned to work on the newly preprocessed dataset (based on our discussion) in the next session.\\n\\nTimeline: Not specific, but in general the sooner the better\\n\\nUsers: Leon Kremers\\n\\nRelevant links:\\nGitHub repo: https://github.com/troselab/Inception-Loops', date=datetime.datetime(2024, 1, 22, 0, 0), scholar='Leon Kremers', topic='Inception Loop pipeline with a focus on preparing Leon‚Äôs data for model training', type='hands'),\n",
       " 'mohammad_030_2024-01-29': ConsultingReport(consultant='mohammad', content='In this session we used a newly exported dataset (based on our discussion in the last session) for model training. While we resolved the issue of invalid loss values we faced in the last session, the model seems to have difficulty training (i.e. the loss does not decrease). Based on this we discussed a way to measure dataset quality: oracle correlation. We then implemented a method to compute oracle correlation and observed that the data does not have a high quality which means we cannot really expect the model to train well.\\n\\nOutcomes: Applied the model on the newly preprocessed dataset. Discussed and implemented oracle correlation as a data quality metric and observed that the data does not have a good quality based on this measure.\\n\\nNext steps: Leon will work on the data so that we get better oracle correlation and we‚Äôll continue working on the data in our next session.\\n\\nTimeline: Not specific, but in general the sooner the better\\n\\nUsers: Leon Kremers\\n\\nRelevant links:\\nGitHub repo: https://github.com/troselab/Inception-Loops', date=datetime.datetime(2024, 1, 29, 0, 0), scholar='Leon Kremers', topic='Inception Loop pipeline with a focus on data inspection and data quality metrics', type='hands'),\n",
       " 'mohammad_031_2024-02-14': ConsultingReport(consultant='mohammad', content=\"There is an Arena, where an Arduino controls optogenetics and valves that release gasses that are used as stimulation in the experiments. There is an Arduino script that controls the LEDs, and the main experimental structure is controlled through MATLAB code. There is also a camera that records the experimental setup. The problem is, when a short experiment (around 1-2 minutes) is done every seventh or the camera recording fails. For longer experiments (5-10 minutes) this failure happens less frequently. One observation they have is that as the camera is recording, the size of the file increases and when the recording is finished the file size is about 100KB, instead of several tens of megabytes. In addition, sometimes during logging, MATLAB freezes, while this is happening the valve pressure stays high, which shouldn't happen. The only solution that could be found to prevent this is turning MATLAB off and turning it on again.\\n\\nNext steps: To have an in person meeting and get a good understanding of the system and how it fails, and with that understanding come up with a plan to resolve the issues.\\n\\nTimeline: Ideally to be solved in one or two months.\\n\\nUsers: Martina and Utsab are working on the system, Martina being the main user.\\n\", date=datetime.datetime(2024, 2, 14, 0, 0), scholar='Martina Canova and Ogulcan Cingiler', topic='Their experimental setup is not exactly working as expected. Mainly software freezes and data is not saved properly.', type='short'),\n",
       " 'mohammad_032_2024-03-13': ConsultingReport(consultant='mohammad', content='In this session we looked at the analysis that Leon has done to imrpove the oracle correlation for the dataset. Even though the  a newly exported dataset does have a slightly higher oracle correlation, upon training the model we still did not see any improvements on the predictive performance (i.e. The model does not learn to predict responses from the input images). We then decided to get a better understanding of Leon‚Äôs preprocessing pipeline such that we can compare to existing preprocessing approaches (i.e. The one used for the Sensorium dataset).\\n\\nOutcomes: Understanding of Leon‚Äôs pipeline to allow us to compare it to other methods.\\n\\nNext steps: Apply other preprocessing pipeline (i.e. The one used for the Sensorium dataset)\\n\\nTimeline: Not specific, but in general the sooner the better\\n\\nUsers: Leon Kremers\\n\\nRelevant links:\\nGitHub repo: https://github.com/troselab/Inception-Loops\\n', date=datetime.datetime(2024, 3, 13, 0, 0), scholar='Leon Kremers', topic='Inception Loop pipeline with a focus on data inspection and data quality metrics', type='hands'),\n",
       " 'mohammad_033_2024-03-14': ConsultingReport(consultant='mohammad', content='In this session we looked at other approaches (i.e.what was used for the Sensorium dataset) for preprocessing the data before applying the. We discuss and implemented the approach and applied it to Leon‚Äôs data. This did not yield a higher oracle correlation, and additionally, upon training the model on this newly preprocessed data, we still did not observe any improvement on the model.\\n\\nOutcomes: Applied other approaches (i.e.what was used for the Sensorium dataset) for preprocessing the data. Did not observe any imrprovements (neither on the oracle correlation nor the predictive power of the model)\\n\\nNext steps: Investigate the steps before the preprocessing steps (e.g. Event detection, deconvolution, etc.)\\n\\nTimeline: Not specific, but in general the sooner the better\\n\\nUsers: Leon Kremers\\n\\nRelevant links:\\nGitHub repo: https://github.com/troselab/Inception-Loops\\n', date=datetime.datetime(2024, 3, 14, 0, 0), scholar='Leon Kremers', topic='Inception Loop pipeline with a focus on data inspection and data quality metrics', type='hands'),\n",
       " 'nick_034_2023-02-04': ConsultingReport(consultant='nick', content=\"\\nWe have started to do pilot experiments based on the open-ephys platform and simultaneously record animal pose using DeepLabCut. Tracking and pose estimation with DLC works very well in our hands, but we have a really hard time getting the physiological recordings (and analyses) to work. Much of the reason is that I am a cell physiologist by training. I have a lot of expertise in slice physiology (patch-clamp), but my troubleshooting skills for extracellular recordings are limited (to say the least üòä).\\n\\nIt would be fantastic if Yuliia could get in touch with you and discuss her project as well as hard-/software integration etc. with you and your team. That would be a huge help, since we are a bit stuck at this point an urgently need some support.\\nwho were describing some troubles they are having with getting a good signal-to-noise ratio in their new electrophysiology setup (implanted tetrodes in a freely-moving mouse setup). \\xa0Due to time constraints, we didn't get too much into the details, but there seem to be some some artifacts from the implanted LED that Yulia has detected, plus perhaps more sources. \\xa0With your hardware background, I thought maybe you might be a good person for them to connect with.\\n\", date=datetime.datetime(2023, 2, 4, 0, 0), scholar='Yulia Turchyna', topic='Extraacellular recordings from the accessory olfactory bulb (a brain region involved in social and sexual information processing) in freely behaving mice. Yuliia (reads in CC) is trying to do perform tetrode recordings and ‚Äì long-term ‚Äì combine them with optogenetic activation / inhibition of principle neurons in this brain area.', type='short'),\n",
       " 'nick_035_2023-03-04': ConsultingReport(consultant='nick', content='\\nLab: Marc Spehr\\n\\n\\n', date=datetime.datetime(2023, 3, 4, 0, 0), scholar='Yulia Turchyna', topic='They had an OpenEphys setup, but couldn‚Äôt work out where the noise was coming from.  The computer was disconnected from the internet, and through troubleshooting we found that it was running an older version of OpenEphys, which didn‚Äôt have plugin supprot.  Once we did an update and installed a power spectrum plugin, we could see 50 Hz noise.  I made reccomendations to get in touch with Trace and see if he could help them reduce their noise.', type='hands'),\n",
       " 'nick_036_2023-06-28': ConsultingReport(consultant='nick', content='\\n: 1-on-1 discussion on (a) potential improvement of previously developed imaging+behaviour processing pipeline and/or (b) current development of behavioural quantification Python package.\\n\\nOliver.Barnstedt@dzne.de &lt;Oliver.Barnstedt@dzne.de&gt;\\nPostdoc, Interested in polishing https://github.com/obarnstedt/MouseFlow\\n\\n\\\\# import deepgraphpose: improved probabalistic version of dlc\\nhttps://github.com/paninski-lab/deepgraphpose\\nhttps://book.morgen.so/nickdelgrosso/mouseflow-refactoring\\n', date=datetime.datetime(2023, 6, 28, 0, 0), scholar='Oliver Barnstedt', topic='', type='short'),\n",
       " 'nick_037_2023-06-30': ConsultingReport(consultant='nick', content='\\n\\n[<ins>https://gist.github.com/raulqf/f42c718a658cddc16f9df07ecc627be7</ins>](https://gist.github.com/raulqf/f42c718a658cddc16f9df07ecc627be7)\\n\\n`git rm --cache <file to remove)\\n\\nCEBRA\\n\\n', date=datetime.datetime(2023, 6, 30, 0, 0), scholar='Oliver Barnstedt', topic='Mouseflow Refactoring:', type='hands'),\n",
       " 'nick_038_2023-03-07': ConsultingReport(consultant='nick', content='\\n\\n\\n', date=datetime.datetime(2023, 3, 7, 0, 0), scholar='Oliver Barnstedt', topic='Mouseflow Refactoring:', type='hands'),\n",
       " 'nick_039_2023-05-07': ConsultingReport(consultant='nick', content='\\nPaired Programming session/1on1 meeting CIDA (Calcium Imaging Data Analysis) focus group\\n', date=datetime.datetime(2023, 5, 7, 0, 0), scholar='Lena Gschossmann', topic='', type='short'),\n",
       " 'nick_040_2023-12-07': ConsultingReport(consultant='nick', content='\\n\"Hi, I\\'m a PhD student from AG Krabbe and AG Blaess. Currently in AG Krabbe we are design and building a new behavior paradigm and I would like to ask the platform from some help since I\\'m a completely newbie when it comes to this. Do you have some time next week that we can meet? So I can show you how the paradigm goes and in what aspects I new help.\\nThank you in advance\\n- Hardware arduino boxes\\n- Software: want arduino behavior to be more reliable\\n- Ben, in lab, is coder and has helped out\\n\\n1\\\\. control platform\\'s movement and send output for sound to be played\\n2\\\\. tell server motors to open the doors\\n\\nNow the monster moves uncontrollably. Want that it moves only when it gets an output given to it (some key).\\n\\nNow the monster moves uncontrollably. Want that it moves only when it gets  given to it (some key).\\n\\nNow: the white noise sound plays, but not linked\\n\\nWant: that sound plays when monster stops moving\\n\\n', date=datetime.datetime(2023, 12, 7, 0, 0), scholar='Catarina Pacheco', topic='', type='short'),\n",
       " 'nick_041_2023-07-18': ConsultingReport(consultant='nick', content='\\n\\n', date=datetime.datetime(2023, 7, 18, 0, 0), scholar='Catarina Pacheco', topic='Learning to program Arduino, use VSCode for Git version control, and how to wire things up using a breadboard.  Got button control of device, which was later adjusted to work with BNC input using Trace‚Äôs help.', type='hands'),\n",
       " 'nick_042_2023-07-19': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 7, 19, 0, 0), scholar='Lena Gschossman', topic='', type='short'),\n",
       " 'nick_043_2023-07-20': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 7, 20, 0, 0), scholar='Catarina Pacheco', topic='Arduino Programming Session 2', type='hands'),\n",
       " 'nick_044_2023-02-08': ConsultingReport(consultant='nick', content='\\n\\n', date=datetime.datetime(2023, 2, 8, 0, 0), scholar='Catarina Pacheco', topic='Arduino Programming Session 3: Controlling motors.', type='hands'),\n",
       " 'nick_045_2023-08-30': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 8, 30, 0, 0), scholar='Alana Darcher', topic='Wants feedback on methods paper on a DataJoint database-based computational pipeline she set up for her PhD project.', type='short'),\n",
       " 'nick_046_2023-08-30': ConsultingReport(consultant='nick', content='\\nWe discussed the latest draft of your manuscript, focusing on the high-level concerns\\xa0of the paper, including:\\n\\nWho is the intended audience?\\xa0 We did a persona creation exercise to help get a sense of what topics and background information would be relevant, needed, and perhaps out of scope for the paper.\\nWhat is needed in the intro to connect with the audience?\\xa0 We did a gut reaction exercise, looking\\xa0at another publication around a similar topic\\xa0to get a sense of what \"not\" to do, to help prioritize certain elements of the paper\\nWhat is the scope of the paper?\\xa0 Generally, we focused the discussion around questions of project scope and the technical needs for remote\\xa0collaboration in a multi-stage pipeline, walking through various approaches that you used in your own\\xa0project as you encountered increases in scope.\\xa0 For example, the need for a single source of truth in both\\xa0data and code, flexibility in version updates while maintaining reliable interfaces, remote access, etc.\\nWhat are some concepts that can be helpful to organize around?\\xa0 Since the challenges focused around remote collaboration, I suggested a high-level concept focused around team roles (Data Engineer, Data Scientist, and Machine Learning Engineer) and their places in a pipeline.\\xa0 Since each team role has the same technology units to their job\\xa0(a data interface code source, a code repository,\\xa0a data storage location, and a data interface code sink), with unique technical requirements around each depending on the project and team.\\nHow can we organize the paper?\\xa0 We ended up with a simple technology project report template for the outline (Motivations and General\\xa0Background, Project Outcome, Problems, Solutions, Further Discussion)\\n\\n\\nNext Steps\\n\\nI hope this discussion helped you with the next stage of your writing!\\xa0 If you would like to meet again for a short, please feel free to book a session at\\xa0https://calendly.com/delgrosso-nick/short-chat.\\xa0 You can also get other iBOTS team members and get their input at\\xa0https://calendly.com/ibots/short-chat.\\xa0 Depending on your needs and interests, another morning session or two could be arranged afterward.\\n\\n', date=datetime.datetime(2023, 8, 30, 0, 0), scholar='Alana Darcher', topic='Reviewed paper', type='hands'),\n",
       " 'nick_047_2009-06-08': ConsultingReport(consultant='nick', content=\"\\nHi, I'm Yonatan from this team: https://ibehave.nrw/our-team/bach-group/\\nand would like to discuss about our camera set up.\\nI will explain a bit about our set up:\\n* We have 10 Ximea cams (MC023CG-SY) that will receive triggers from the Unity(VR) over the network through the LabStreamingLayer(https://labstreaminglayer.org/#/) to start and stop recording.\\n* Currently we use the ximea API in python (https://www.ximea.com/support/wiki/apis/python) as the interface to utilize the cameras (send command to set parameters, start stop acquisition) and openCV library for some image processing.\\n\\nResearch context: *Human escape behavior in VR.\\n\\nOur goal: *We want to record the video at 60 fps, full HD resolution, and RGB24 format.\\nCurrent issue: * The frame rate drops significantly as we incease the number of cameras.\\nIt was a pleasure talking with you today; your setup sound really interesting! Just to summarize (so I make sure I understand correctly), there is currently a challenge around getting some software to acquire all 10 cameras at full resolution and 60fps, and that it is clear that it isn't a hardware issue because the company's proprietary software seems to be doing it well on the same system.\\xa0To help track down this problem and learn more together, we agreed to set aside some time together in person to\\xa0troubleshoot the system\\xa0for 3 morning\\xa0sessions!\\n\\n\", date=datetime.datetime(2009, 6, 8, 20, 23), scholar='Yonatan Hurtabarat', topic='', type='short'),\n",
       " 'nick_048_2023-07-09': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 7, 9, 0, 0), scholar='Manuel Mittag', topic='Interested in learning Git', type='short'),\n",
       " 'nick_049_2023-08-09': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 8, 9, 0, 0), scholar='Lena Gschossmann', topic='Interested in refactoring Matlab code into a GitHub Repo', type='short'),\n",
       " 'nick_050_2023-09-13': ConsultingReport(consultant='nick', content=\"\\nWe worked through benchmarking the cameras and the Ximea Python API, finding exactly what you reported (it's slower to access more cameras, with higher resolutions).\\xa0 We then showed that using multiple processes, the cameras could be accessed at full speed!\\xa0 We also found that OpenCV's window show() works great across multiple processes.\\n\\nSome questions still remain:\\n- Why does time.sleep(.0000000001) create such delays?\\xa0 (Theory: other processes are taking over.\\xa0 The high CPU access indicates that may be the issue)\\n- How to stream data to the hard drive without slowing down the cameras?\\xa0 (Theory: since the hard drive wasn't maxed out, it may not be the VideoWriter.write() that's the bottleneck here).\\n\\nFuture Directions\\n\\nYou mentioned that you have a conference coming up and can't meet in the next few weeks, so if you'd like to meet again, tthe next step would be to schedule a short (https://calendly.com/delgrosso-nick/short-chat) for when you're available again; then we can talk over things and plan another session (or series of sessions, depending on what you're interested in doing).\\xa0 If I'm not available, you can also reach the rest of the iBOTS at\\xa0https://calendly.com/ibots/short-chat\\n\\n\\n\", date=datetime.datetime(2023, 9, 13, 0, 0), scholar='Yonatan Hutabarat', topic='Coding Camera Control', type='hands'),\n",
       " 'nick_051_2023-09-13': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 9, 13, 0, 0), scholar='Yonatan Hutabarat', topic='Coding Camera Control', type='hands'),\n",
       " 'nick_052_2023-09-13': ConsultingReport(consultant='nick', content='\\n\\n', date=datetime.datetime(2023, 9, 13, 0, 0), scholar='Anoushka Jain', topic='???', type='short'),\n",
       " 'nick_053_2023-09-25': ConsultingReport(consultant='nick', content='\\n[SchematicOverview_AnalysisPipeline_Lena.pdf](../_resources/SchematicOverview_AnalysisPipeline_Lena.pdf)\\n\\n\\n\\n\\n', date=datetime.datetime(2023, 9, 25, 0, 0), scholar='Lena Gschossmann', topic='', type='hands'),\n",
       " 'nick_054_2023-10-10': ConsultingReport(consultant='nick', content='\\nSet work-plan: git/GitHub workflows, troubleshooting and modifying CaImAn to be less RAM-hungry, docker image creation, working with clusters\\n', date=datetime.datetime(2023, 10, 10, 0, 0), scholar='Manuel Mittag', topic='', type='short'),\n",
       " 'nick_055_2023-10-10': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 10, 10, 0, 0), scholar='Yonatan Hurtabarat', topic='continuing the sessions for ximea camera problems at bachlab.', type='short'),\n",
       " 'nick_056_2023-12-10': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 12, 10, 0, 0), scholar='Lena Gschossmann', topic='Collaboration with GitHub', type='hands'),\n",
       " 'nick_057_2023-10-16': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 10, 16, 0, 0), scholar='Yonatan Hutabarat', topic='Writing library with Yonatan', type='hands'),\n",
       " 'nick_058_2023-10-19': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 10, 19, 0, 0), scholar='Manuel Mittag', topic='Introduction to Git', type='hands'),\n",
       " 'nick_059_2023-10-19': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 10, 19, 0, 0), scholar='Yonatan Hutabarat', topic='Programming Camera API', type='hands'),\n",
       " 'nick_060_2023-10-26': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 10, 26, 0, 0), scholar='Yonatan Hutabarat', topic='Multiprocessing Python, Multi-Camera Control', type='hands'),\n",
       " 'nick_061_2023-10-30': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2023, 10, 30, 0, 0), scholar='Lena Gschossmann', topic='Multi-Repo Collaborations, Git-based Dependency Management strategy with Matlab', type='hands'),\n",
       " 'nick_062_2023-10-31': ConsultingReport(consultant='nick', content='\\n\\n', date=datetime.datetime(2023, 10, 31, 0, 0), scholar='Yonatan Hutabarat', topic='Multiprocessing Python, Multi-Camera Control', type='hands'),\n",
       " 'nick_063_2023-02-11': ConsultingReport(consultant='nick', content='\\n\\n\\n', date=datetime.datetime(2023, 2, 11, 0, 0), scholar='Yonatan Hutabarat', topic='Finishing up Library', type='hands'),\n",
       " 'nick_064_2024-08-01': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2024, 8, 1, 0, 0), scholar='Sarah Morsy', topic='Statistical Analysis with R: PERMANOVA on metabolomics data', type='short'),\n",
       " 'nick_065_2024-01-16': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2024, 1, 16, 0, 0), scholar='Sarah Morsy', topic='Statistical Analysis with R: PERMANOVA on metabolomics data', type='hands'),\n",
       " 'nick_066_2024-01-17': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2024, 1, 17, 0, 0), scholar='Sarah Morsy', topic='Statistical Analysis with R: PERMANOVA on metabolomics data', type='hands'),\n",
       " 'nick_067_2024-03-21': ConsultingReport(consultant='nick', content='\\n\\n', date=datetime.datetime(2024, 3, 21, 0, 0), scholar='Lena Gschossmann', topic='Discuss a Git & GitHub workshop that she and Bence would like to organize for their lab.', type='short'),\n",
       " 'nick_068_2024-10-04': ConsultingReport(consultant='nick', content='\\n\\nFocused on shortening troubleshooting time intervals; the issue they were dealing with had been a problem for over 6 months, and by reducing the cycle time to under 3 minutes, we were able to start honing in on the problem.', date=datetime.datetime(2024, 10, 4, 0, 0), scholar='Martina Canova and Ogulcan', topic='Troubleshooting Video Recording System', type='hands'),\n",
       " 'nick_069_2024-10-04': ConsultingReport(consultant='nick', content='\\n\\nSome things we discussed today, for your notes:\\n\\nCode Management Tools and the method of using one tool for one purpose:\\nGit\\xa0Repos for seperating projects from one another\\nGit Branches for collaborating and managing risk among developers.\\nGit Tags, GitHub Releases, or PyPI for releasing versioned software to users.\\nTesting Strategies:\\nOutside-In testing: starting with testing the functions that your users run\\nStrategy: Just enough testing to help demonstrate that your project does what it\\'s meant to do.\\nStrategy: Write \"Happy Path\" tests in jupyter notebooks meant as tutorials for your users--free demos and documentation!\\nBottom-Up testing: starting with testing the functions that your code most relies on.\\nStrategy: thoroughly test the functions that your code most relies on & poses the most risk and debugging time to your project\\nApproval (e.g. Golden Master / Golden Snapshot) Testing: writing automated\\xa0tests that only detect if something has changed, not if something is correct.\\nStrategy: useful when refactoring, but a hindrance when trying to improve code.\\nUser\\xa0Documentation:\\nIt\\'s for the users!\\xa0 As long as it\\'s easily discoverable, easy to access,\\xa0easy to understand, and accurate, any documentation platform works.\\nThe \"accurate\" part is tough: keep in mind that managing documentation is part of managing code, and look for opportunities to make that process easier for yourself.\\n\\n', date=datetime.datetime(2024, 10, 4, 0, 0), scholar='Mahan Hosseini', topic='Git Repo organization and automated testing for python project release.', type='short'),\n",
       " 'nick_070_2024-04-17': ConsultingReport(consultant='nick', content='\\n\\n\\nRelease Code\\nCurrently has script, will put into functions\\nMake a notebook to demo\\nProvide some test data\\nInclude dependencies\\nReorganize Code\\nMake nicely-organized functions\\nReduce Memory Footprint\\nvectorization\\n\\n', date=datetime.datetime(2024, 4, 17, 0, 0), scholar='Theodoros Tamiolakis', topic='Wants to publish and release a repo that does place cell analysis', type='short'),\n",
       " 'nick_071_2024-04-22': ConsultingReport(consultant='nick', content='\\n\\nFolder reorganization\\nSetup.py overview, pip ‚Äìe workflow\\nPytest.ini settings\\nGitHub Actions Implementation\\n\\n', date=datetime.datetime(2024, 4, 22, 0, 0), scholar='Mahan Hosseini', topic='Git Repo organization and automated testing for python project release.', type='hands'),\n",
       " 'nick_072_2024-04-30': ConsultingReport(consultant='nick', content='\\n\\n\\nDiscussions around unit testing and software architecture.\\nSkip tests with data that hasn‚Äôt been approved to be in the git repo using @pytest.mark\\nMoving generated test data to a temporary directory using the `tmp_path` fixture\\nLearning about `pdb` and how to use the debugger in pytest with `‚Äîpdb`\\nLots of discussions around infrastructure\\nRemoving global variables from tests\\n\\n\\n', date=datetime.datetime(2024, 4, 30, 0, 0), scholar='Mahan Hosseini', topic='Using pytest fixtures for his approval tests', type='hands'),\n",
       " 'nick_073_2024-04-17': ConsultingReport(consultant='nick', content='\\n\\nOrganized notebooks into ‚Äú./notebooks‚Äù\\nAdded ‚Äúsys.path.append(‚Äò..‚Äô) to import from the local library\\nTaught sys.path\\nPut data files into `./data`\\nAdded ‚Äúdata/input_data.json‚Äù to gitignore\\nAdded an ‚Äúdata/example.json‚Äù template as data structure documentation\\nTaught gitignore\\nAdded `requirements.txt`\\nSorted imports in notebooks into built-in, third-party, and project\\nManually wrote requirements file\\nAdded `>=` to version numbers, using the lockfile his colleague created as a reference\\n\\nAdded `.bat` files with virtual environment tasks for reference\\n‚Äúcreate_environment.bat‚Äù\\n‚Äúactivate_environment.bat‚Äù\\n‚Äúinstall_requirements.bat‚Äù\\nCame up with a simple strategy for making a workflow notebook that calls other notebooks\\n`if locals().get(‚Äòscript_mode‚Äô, TRUE): parsms = ‚Äúwhatever‚Äù`\\n\\nWants to follow up by refactoring things into scripts next time.\\n\\n', date=datetime.datetime(2024, 4, 17, 0, 0), scholar='Theodoros Tamiolakis', topic='Wants to publish and release a repo that does place cell analysis', type='hands'),\n",
       " 'nick_074_2024-04-30': ConsultingReport(consultant='nick', content='\\n\\nFrom:\\n\\nTo:\\n\\n\\n', date=datetime.datetime(2024, 4, 30, 0, 0), scholar='Fatemeh Zousefi', topic='centralized automated pipeline for experimental systems', type='short'),\n",
       " 'nick_075_2024-02-05': ConsultingReport(consultant='nick', content='\\n\\n\\nWant daa we can immediately identify:\\nShould be immediately available\\nCurrently:\\nGood:\\nPeople manually copy the data to a lab server within 1-2 days of the end of the session\\nAnimal Name + Date\\nNotes are scanned and saved at the end of an experiment (some have to be hand-written)\\nElectronic lab notebooks are also used.\\nBad:\\nMost notes aren‚Äôt immediately available\\nDifferent file formats for everyone\\nSimilar format for analysis\\nCurrent: minscope data is in same format\\nMultiple formats used in raw, multiple after preprocessing\\nAgreements around certain steps in pre-processing, but some inconsistencies in the process\\nEveryone uses the same code at the moment for pre-processing (e.g. motion correction)\\nAnalysis\\nMostly different\\nSuggested:\\nPicking some quality control metrics\\nArchive format\\nWould like to add code management practices\\nUrrently everyone pretty much on their own, though do have\\n\\n\\nProposal:\\n', date=datetime.datetime(2024, 2, 5, 0, 0), scholar='Isaac, Sabine Krabbe, and Natalia', topic='centralized automated pipeline for experimental systems', type='short'),\n",
       " 'nick_076_2024-02-05': ConsultingReport(consultant='nick', content='\\n\\nRose group\\n\\nWe got a sandbox notebook running that logged into the database and imported the database schema, then:\\nExplored the table definitions of multiple tables\\nFetched data from the tables\\nConverted fetched data to Pandas Dataframes\\n\\nThen, we copy-pasted a problematic set of queries into its own notebook to make a sandbox, then I helped her break down the query into multiple small steps.\\n\\nThis one was a difficult session, mostly because I jumped into the hands-on portion directly (upcoming holiday and all that, and rather small case)\\n\\n', date=datetime.datetime(2024, 2, 5, 0, 0), scholar='Natalia Krasilshchikova', topic='I have difficulties in navigating in the data in datajoint pipeline.', type='short'),\n",
       " 'nick_077_2024-06-06': ConsultingReport(consultant='nick', content='\\n\\nWants to automate more by breaking things down into functions.  Tried optimizing for performance already, but started getting issues (different results) and not sure.\\n\\nMade 6 functions with him, all centered around plotting.  In the next month, he‚Äôll continue making functions, and then I‚Äôll meet with him again to work on the harder-to-move parts.\\n\\n\\n', date=datetime.datetime(2024, 6, 6, 0, 0), scholar='Theodoros Tamiolakis', topic='Wants to publish and release a repo that does place cell analysis', type='hands'),\n",
       " 'nick_078_2024-08-05': ConsultingReport(consultant='nick', content='\\n\\nHas experience with:\\n**Snakemake (project), NextFlow (tutorial-level)\\n\\nInterested in NWB files:\\nSo, let‚Äôs use them!\\n\\n\\nAlso mentioned that nwb files\\n\\n\\nNote: later on I created a similar workflow from memory, to be used as a broader template in the future: https://github.com/nickdelgrosso/pipeline-demo1\\n', date=datetime.datetime(2024, 8, 5, 0, 0), scholar='Isaac Racine', topic='', type='short'),\n",
       " 'nick_079_2024-05-13': ConsultingReport(consultant='nick', content='\\n\\nTest parameterization on unit tests\\nPytest.mark.parametrize\\nHypothesis.strateges\\nTest fixture: setup test data files\\n\\n\\nForks > pulls current version > changes something on new branch > opens pull request\\n', date=datetime.datetime(2024, 5, 13, 0, 0), scholar='Mahan Hosseini', topic='Using pytest fixtures for his approval tests', type='hands'),\n",
       " 'nick_080_2024-04-06': ConsultingReport(consultant='nick', content='\\n\\nIsaac has been trying to understand calcium analysis, and has gotten a bit scattered since the last time I saw him (a month ago, before my holiday).  He‚Äôs gotten some example files, and wants to start on motion correction, though.  He shared an overview of his understanding of the analysis (first screenshot), and I talked with him and Natalia until we ended up with something a little more detailed.  (second screenshot).  The plan is to meet another four times, once per week, building up a pipeline with the following steps:\\n1. Transfer Incscopix image files to Tiff files, then Downsample and spatial-filter the tiff files, to make motion correction easier.\\nThought: Why not HDF5 files, instead?\\n2. Perform Motion correction with Caiman\\n3. Make reports on the motion correction, using statistics on the quality of motion correction as part of the report.\\nNote: the pipeline should also have access to theses statistics, triggering re-runs if the quality of the motion correction wasn‚Äôt up to snuff.\\nNote2: Reruns should not overwrite previous runs.\\n4. Add a motion correction parameters file, which researchers can add suggestions to so that good reference frames and the right motion correction method can be used in the processing pipeline.\\n\\nNew tool: ‚ÄúCiatah‚Äù https://github.com/bahanonu/ciatah, does rigid motion correction in matlab\\nNew tool: https://github.com/inscopix/py_isx: python tool for\\n\\n:\\n\\n', date=datetime.datetime(2024, 4, 6, 0, 0), scholar='Isaac Racine & Natalia Vazquez', topic='Preprocessing Steps', type='short ‚Äî Inter-Project Update'),\n",
       " 'nick_081_2024-11-06': ConsultingReport(consultant='nick', content='\\n\\n\\nWorked with Isaac on interpreting the .isdx file format from inscopix.  This was a very long pair programming sesssion, where we created a notebook and went through the bytes of the example file, extracting the footer (utf-8-encoded json data, with a couple of static bytes at the end to indicate how long it is), the image data (uint16 array), and what we discovered to be metadata around every frame.  Much time was spent trying to investigate the size and nature of the frame header and footer, and only some success was had.\\n\\n', date=datetime.datetime(2024, 11, 6, 0, 0), scholar='Isaac Racine', topic='Exporting Data from Inscopix', type='hands'),\n",
       " 'nick_082_2024-06-18': ConsultingReport(consultant='nick', content='\\n\\nWe converted the scratch code over to a proper library.  Reviewed pytest, pyproject.toml, python package structure.  Worked well!\\n\\nOne neat teaching trick I tried out: teaching property testing first before unit testing.  That went over **way** better than starting with unit testing. I didn‚Äôt use Hypothesis, just directly did a property test in pytest.\\n\\n', date=datetime.datetime(2024, 6, 18, 0, 0), scholar='Isaac Racine', topic='Writing Inscopix Reading Library using TDD and the monorepo pattern', type='hands'),\n",
       " 'nick_083_2024-06-18': ConsultingReport(consultant='nick', content='\\n', date=datetime.datetime(2024, 6, 18, 0, 0), scholar='Ceci Herbert', topic='Course Planning', type='short'),\n",
       " 'nick_084_2024-03-07': ConsultingReport(consultant='nick', content='\\n\\n', date=datetime.datetime(2024, 3, 7, 0, 0), scholar='Isaac Racine', topic='Discuss integration development of pipeline', type='hands'),\n",
       " 'nick_085_2024-04-07': ConsultingReport(consultant='nick', content='Manuel is teaching a Python workshop in a couple of days!  He wants help setting up his github repo, setting up installation of libraries for the students, and hosting his data for the course.  We got it all set up!  Used Nextcloud, but he didn‚Äôt have enough space (needed 4.5 GB, only had 2GB left).  Suggested google drive.\\nWent well!  Just needed some quick setup help.\\n\\n\\n\\n', date=datetime.datetime(2024, 4, 7, 0, 0), scholar='Manuel Mittag', topic='Course Planning', type='short'),\n",
       " 'nick_086_2024-04-07': ConsultingReport(consultant='nick', content='Sarah wants to have more options for statistical analysis than the softare she currently has available.  She‚Äôs found a package she likes, but is unsure about the instructions for installing from github.  So, we went over:\\n- how a GitHub repo is organized on the webiste,\\n‚Äì How to find the releases and download it\\n-  How to use `install.packages()` to install a release from a local path.\\nThen, we went over how vignettes, the package help, and data examples work in R.  I encouraged her to play with the examples that the devs give her first, before applying the project to her own data.\\nShe says she‚Äôll contact me next week or so again, once she‚Äôs got something with her own data.\\n\\n', date=datetime.datetime(2024, 4, 7, 0, 0), scholar='Sarah Morsy', topic='Installing R Packages from GitHub', type='short'),\n",
       " 'nick_087_2024-07-16': ConsultingReport(consultant='nick', content='Isaac‚Äôs got motion correction running now and included in a pipeline, including a great example of using Snakemake‚Äôs ‚Äòcheckpoint‚Äô system.\\n\\nTopics discussed:\\nWhat is metadata?  Isaac had attended the Helmholtz Roadshow and saw a lot of emphasis on metadata, wasn‚Äôt sure if he hsould take it seriously.  I said yes!  I gave him a quick summary of different kinds of metadata in scientific research and why they are important to manage, and how the apply to his project.\\nWhat problems can come up during the migration to the lab server?\\nPermission errors\\nData hosting differences\\nDifferent operating systems\\nInstallation steps\\nUser availability differences\\nGraphical enviornment availability differences.\\nHe started the migration using git, learned:\\nGit fetch command (used to find his branch)\\nHe needs a password to access the filesystem, didn‚Äôt know his password.\\n\\nAnd...that password not working prevented him from being able to get working, so we stopped the meeting about an hour in.  I‚Äôll see him again in a few weeks, when he‚Äôs back from his holidays.\\n\\n\\n', date=datetime.datetime(2024, 7, 16, 0, 0), scholar='Isaac Racine', topic='Managing Metadata in a Pipeline and Migrating to a Lab Server', type='hands'),\n",
       " 'sangeetha_088_2024-05-01': ConsultingReport(consultant='sangeetha', content='\\nCloud Storage Options: The main goal of the meeting was to identify an appropriate cloud storage solution that meets the data sharing and collaboration needs effectively.\\nPreferred Solution: Preference is to opt for a solution that is both free and user-friendly.\\nData Sharing and Permissions: Currently, there is a requirement to share around 15GB of data with another group. The focus is on enabling the second group to download existing data and contribute new content to the same database.\\nExplored Storage Platforms: The platforms discussed included Mega, Dropbox, Google Drive, and Sciebo.\\nUseful link for Sciebo: https://wwuit-sys.zivgitlabpages.uni-\\nmuenster.de/sciebo/docs/teilen/projektboxen/\\nhttps://hochschulcloud.nrw/de/hilfe/windows/synchronisation.html\\nA table consolidating cloud storage options was sent to Moritz post-meeting\\n', date=datetime.datetime(2024, 5, 1, 0, 0), scholar='Moritz Haustein', topic='Hi, we recently started a collaboration with a research group in W√ºrzburg and need to transfer data files (mostly marker annotations for videos and other metadata) forth and back. I thought about a cloud solution with synchronization option for both sides. So, I would like to get your ideas on what service/solution would be best for us. Looking forward to meet you. Moritz', type='short'),\n",
       " 'sangeetha_089_2023-08-31': ConsultingReport(consultant='sangeetha', content='\\nWhether she was eligible to attend: She is not part of iBehave labs but collaborates with one of them. Since she is part of a German university, she was still eligible to attend our workshop.\\nAfter speaking with iBOTS-Code team, I sent out an email to Madhuri assuring her of approval of her registration to the course.\\nShe was working on a publication and she wanted to discuss more on how to automate some of the tasks. I sent an email with a link to book a session where we could discuss about how to do it together.\\nMeeting Outcome:\\nShe registered and participated in our Intro to Python workshop.\\n\\n', date=datetime.datetime(2023, 8, 31, 0, 0), scholar='Madhuri Puvvada', topic='Regarding 5-day workshop', type='short'),\n",
       " 'sangeetha_090_2023-09-26': ConsultingReport(consultant='sangeetha', content='\\nI proposed the idea for organizing an iBOTS software engineering book club together and welcomed her input to make it better.\\nI also sent her a shared link to a Google Sheet Book Club Planner. It is a basic spreadsheet wherein we both had option to input book titles and number of chapters and it would perform simple calculations that could help us plan our sessions.\\nAnoushka made some suggestions\\nSend out a form to find out how many people are interested.\\nHave some hand-on sessions to make the club more attractive.\\nAnoushka was also concerned about her own projects and the timeline of the club.\\nBoth of us agreed that this is something we would like to go on for a long time.\\nOur action items were\\nAnoushka: Get back to Sangeetha on how much time she can dedicate to the club and her preferred start date.\\nSangeetha: Speak with Nick and iBOTS-Code about our new plan to confirm whether it is still within what iBOTS offer to researchers.\\nAfter the above discussion, Anoushka spoke about her own code and how she would like some help with refactoring it. She mentioned that she would like to get it done as soon as possible due to two reasons:\\nShe had to start with her PhD work as soon as she was done with finishing up her masters work which was the code.\\nThe code already had many users and another group was interested to incorporate her code into their own codebase.\\nI offered to help with that and we scheduled an external meeting (short-chat) to discuss this. To be noted: This was not done through calendly.\\n\\n', date=datetime.datetime(2023, 9, 26, 0, 0), scholar='Anoushka Jain', topic='Club discussions', type='short'),\n",
       " 'sangeetha_091_2023-09-27': ConsultingReport(consultant='sangeetha', content='\\nAnoushka showed her code and explained that she wants it to be modularized better.\\nShe was working on multiple branches and was worried about merging them on github.\\nAnoushka was also interested to improve Active Learning algorithm that was part of her code but we decided to work on it after we finish refactoring the code as it would be easier to add features.\\nWe agreed to have three hands-on sessions. Two sessions would be for refactoring the code and the last session would be for merging our changes on Github.', date=datetime.datetime(2023, 9, 27, 0, 0), scholar='Anoushka Jain', topic='Modularizing code', type='short'),\n",
       " 'sangeetha_092_2023-09-27': ConsultingReport(consultant='sangeetha', content='\\nElisa and Michael spoke about their plan for the Hackathon and the Bootcamp. They shared the schedule and participants registered for the Bootcamp.\\nElisa also asked if we had some exercise sheets that could be sent out to Bootcamp registrants which was a requirement for their participation in the event.\\nOriginally, the plan was that iBOTS will team will teach Python to the Bootcamp participants. Elisa and Michael had shared a dataset earlier for this purpose.\\nAs there were only 5 to 7 participants registered for the Bootcamp, Nick offered an alternative to the original plan: iBOTS will provide a dataset and the participants will work on projects together during the event. At the end of the event, they will give a small presentation. Elisa and Michael agreed.\\nElisa said that it was not highly necessary to meet again to discuss the dataset.\\nAction item:\\nElisa will send a PDF of the schedule.\\nNick will mail exercises to Elisa to be sent out to the Bootcamp registrants.', date=datetime.datetime(2023, 9, 27, 0, 0), scholar='Elisa Lilly Garulli', topic='Exercise sheet for Retune Hackathon', type='short'),\n",
       " 'sangeetha_093_2023-04-10': ConsultingReport(consultant='sangeetha', content='\\nAnoushka went over different modules in her code.\\nWe identified the most pressing feature that she was interested in refactoring (ask Anoushka which one if she remembers).\\nWe made a new branch for the feature on git and github.\\nI asked her if she would be interested in doing a mob  programming session and explained what it was.\\nShe wanted to try it out. She was already familiar with VS Code live sharing feature which we used for mob programming.\\nWe refactored a few functions taking turns to be navigator and typer.\\nWe made a commit for every new function.', date=datetime.datetime(2023, 4, 10, 0, 0), scholar='Anoushka Jain', topic='Code refactor', type='hands'),\n",
       " 'sangeetha_094_2023-05-10': ConsultingReport(consultant='sangeetha', content='\\nWe identified the a feature to refactor (ask Anoushka which one if she remembers).\\nWe made a new branch for the feature on git and github.\\nI suggested that we do not do mob programming session. We still used VS Code live sharing feature to collaborate but I did not use type as much as Anoushka.\\nWe made a commit for every new function.\\nAt the end of the session, Anoushka was happy with the changes we made and wanted to book a final session to work on merging the new changes.', date=datetime.datetime(2023, 5, 10, 0, 0), scholar='Anoushka Jain', topic='Coding session', type='hands'),\n",
       " 'sangeetha_095_2023-09-10': ConsultingReport(consultant='sangeetha', content='\\nI spoke about change in the original idea of the Book Club. Instead of a book club, we wanted to make it into a learning club.\\nThe idea was that we meet during lunch break and learn something related to coding. There would be one or more person sharing a library or anything related to programming or software engineering and the rest would learn. Anoushka was still interested in this.\\nWe also discussed about what we would like to get out of the club. Anoushka was interested in learning more about OOP and testing.', date=datetime.datetime(2023, 9, 10, 0, 0), scholar='Anoushka Jain', topic='Book club', type='short'),\n",
       " 'sangeetha_096_2023-10-09': ConsultingReport(consultant='sangeetha', content='\\nAs per Anoushka‚Äôs prior meeting with her supervisor, she wanted to work on the bug in her active learning code before merging the changes.\\nWe spent some time going through that part of the code.\\nAnoushka explained that she was not getting the expected level of accuracy in her code after she made a few changes.\\nWe identified few small bugs in splitting of training and test datasets in loops. However, fixing it did not solve the issue.\\nI offered to bring in Mohammad for the next session as he had experience working in ML and Anoushka was happy with that.\\nAction items:\\nAnoushka wanted to get more results before working on the next session\\nSangeetha has to speak with Mohammad to see his availability.\\nMeeting Outcomes\\nI sent Anoushka Mohammad‚Äôs booking link. Originally, both Mohammad and I were supposed to be in the session. But due to other consulting bookings, only Mohammad was part of the sessions.\\nAnoushka and Mohammad had 2 to 3 session together after this.', date=datetime.datetime(2023, 10, 9, 0, 0), scholar='Anoushka Jain', topic='PR stuff', type='hands'),\n",
       " 'sangeetha_097_2023-09-26': ConsultingReport(consultant='sangeetha', content='\\nAlexander ran a learning club in Julich. In each session , one of the participants shared a piece of code with the rest of the group.\\nThe shared code went into a github repo: Module Of The Week\\nI spent some time going over my own plan for the club and Alex offered a few suggestions:\\nMake a github repo\\nI am welcome to use their own repo for inspiration\\n', date=datetime.datetime(2023, 9, 26, 0, 0), scholar='Alexander Kleinjohann', topic='Learning Club organisation', type='short'),\n",
       " 'sangeetha_098_2023-11-20': ConsultingReport(consultant='sangeetha', content='\\nIn person meeting at the DZNE\\nSarah wanted to learn how to do wald‚Äôs test in Python, data analysis process in python, and data visualization.\\nI suggested that we pick Wald‚Äôs test and try to incorporate the other two especially the data visualization part but we try and focus on how to do Wald‚Äôs test. Sarah agreed.\\n', date=datetime.datetime(2023, 11, 20, 0, 0), scholar='Sarah Morsy', topic='', type='short'),\n",
       " 'sangeetha_099_2023-11-23': ConsultingReport(consultant='sangeetha', content='\\nWe took a session to understand the dataset used by the template code\\nWe compared the sample dataset to Sarah‚Äôs data and identified features of interest\\n', date=datetime.datetime(2023, 11, 23, 0, 0), scholar='Sarah Morsy', topic='', type='hands'),\n",
       " 'sangeetha_100_2023-11-27': ConsultingReport(consultant='sangeetha', content='\\nKaren has a Matlab code that is used for data acquisition from her experiment.\\nData acquisition was delayed by between 10-20 seconds per iteration.\\nShe wanted to work together to identify bottlenecks and reduce delays\\nWe decided to have one hands-on session to work on it together.', date=datetime.datetime(2023, 11, 27, 0, 0), scholar='Karen Cheng', topic='Matlab data acquisition toolbox ‚Äì acquisition delays', type='short'),\n",
       " 'sangeetha_101_2023-11-29': ConsultingReport(consultant='sangeetha', content='\\nWe spent some time installing R and R studio in Sarah‚Äôs computer. Sarah and I spent significant portion of the hands-on trying to install the DESeq2 library.\\nBy the end of the session, we figured out that DESeq2 library works with a specific R version. Sarah installed it by herself after the session.', date=datetime.datetime(2023, 11, 29, 0, 0), scholar='Sarah Morsy', topic='R Code help', type='hands'),\n",
       " 'sangeetha_102_2023-04-12': ConsultingReport(consultant='sangeetha', content='\\nWe used Matlab profiler and tic toc to time individual sections of the code\\nAfter identifying where the code is lagging, we tried multiple approaches to solve them\\nUsed vectors instead of loops in some places\\nTried to preallocate memory but it was not a good solution to the issue as the final size was unknown\\nWe thought to try out parallel computing for Output\\nWe decided to look into parallel computing in Matlab (and the current issue) separately and have another hands-on session to see if it was a viable solution\\nMeeting outcome\\nOur next meeting was cancelled by Karen due to network problems at her lab.', date=datetime.datetime(2023, 4, 12, 0, 0), scholar='Karen Cheng', topic='Matlab data acquisition', type='hands'),\n",
       " 'sangeetha_103_2023-05-12': ConsultingReport(consultant='sangeetha', content='\\nAfter a meeting with her supervisor, Sarah had some code written in Python using r2python library.\\nShe wanted to modify the code to work with her dataset instead of writing it from scratch in R.\\nWe tried to work on it but we came up with a lot of issues and could not make the code function as intended.\\nThe outcome of the session was that we had curated her dataset such that it could be imported by Python for the rest of the code to work.\\n', date=datetime.datetime(2023, 5, 12, 0, 0), scholar='Sarah Morsy', topic='R code help (Wald‚Äôs test)', type='hands'),\n",
       " 'sangeetha_104_2023-12-18': ConsultingReport(consultant='sangeetha', content='We both agreed that January 5th would be a good date to have kick-off meeting.\\nNote: Eventually, the date was pushed to January 25th.', date=datetime.datetime(2023, 12, 18, 0, 0), scholar='Anoushka Jain', topic='Book club', type='short'),\n",
       " 'sangeetha_105_2023-12-19': ConsultingReport(consultant='sangeetha', content='\\nSarah had a Jupyter notebook with analysis and visualizations\\nShe wanted help with using Pandas to do certain groupby tasks and also to get descriptive statistics\\nWe worked together to learn more about groupby operations and how to do them in Pandas.\\nWe also made some figures with the help of seaborn and Pandas plotting methods.', date=datetime.datetime(2023, 12, 19, 0, 0), scholar='Sarah Morsy', topic='Python data visualization code help', type='hands'),\n",
       " 'sangeetha_106_2023-12-20': ConsultingReport(consultant='sangeetha', content='\\nSarah wanted to get some results for her meeting with her supervisor. She was confused whether to work with the R code or to look for other methods.\\nAs the meeting was on that day, I suggested to work with the same code for half the session but instead of Python we use R to remove additional complexities. I also suggested that we can have another session after lunch (before her meeting with her supervisor) in case things don‚Äôt work out.\\nWe wrote simplest form of the code in R which was around 4 to 5 lines. We used with a simple fake data we made which was structurally similar to the actual dataset and tried the code. This produced no errors and we got the results we expected.\\nWe then used the same code with her data and we got the expected wald‚Äôs test results.\\nHowever, after her meeting with her supervisor, she realized that Wald‚Äôs test was not what she wanted.', date=datetime.datetime(2023, 12, 20, 0, 0), scholar='Sarah Morsy', topic='Wald‚Äôs test', type='hands'),\n",
       " 'sangeetha_107_2023-12-20': ConsultingReport(consultant='sangeetha', content='\\nOgulcan showed me the code and the jupyter notebooks for an analysis. He wanted either of those to work with docker container.\\nI suggested that we have a hands-on session to work on it together and he asked if I am available to start now.\\nWe both spent a few minutes to look up solutions together.\\nEventually, we made the jupyter notebook work with docker container by specifying the ports.\\n\\n', date=datetime.datetime(2023, 12, 20, 0, 0), scholar='Ogulcan Cinglier', topic='Docker and making an old Python2.7 codebase a container', type='short'),\n",
       " 'sangeetha_108_2024-08-01': ConsultingReport(consultant='sangeetha', content='\\nOliver and his team were planning for a caiman imaging workshop.\\nSince iBOTS-Code already advertised for the same workshop, he wanted to collaborate with us.\\nHe offered to speak with Eric Thomson to give a talk at the workshop\\nWe both decided to meet again to speak about the specifics of the workshop\\nI suggested that he can be a TA for the course and can even team some topics.', date=datetime.datetime(2024, 8, 1, 0, 0), scholar='Oliver Barnstedt', topic='CaImAn workshop', type='short'),\n",
       " 'sangeetha_109_2024-12-01': ConsultingReport(consultant='sangeetha', content='\\nMadhuri showed the github page of the library she wanted to use and explained what it does.\\nI suggested that we can have a hands-on session to work on it together. I recommended two sessions: first session to install and run the tutorial notebooks. Second session to work on her own data.\\nWe started with the first session on the same day.\\nWe made a conda environment specifically for the library\\nWe installed the library.\\nRunning the example notebooks from VS Code gave us unexpected results (we could not select region of interests).\\nWe found a streamlit app associated with the code and explored streamlit a bit before we used the app.\\nWe found that it needs OpenAI access token that Madhuri already had. We tried but it gave an error.\\nWe narrowed it down to the fact that she didn‚Äôt have paid version. I had a paid version but it did not work with that access token either.\\nEventually we figured out that we have to add credits (pay for extra features) to access API.\\nMadhuri wanted to try it out in the next hands on. In the meantime, she would get access token with credits.', date=datetime.datetime(2024, 12, 1, 0, 0), scholar='Madhuri Puvvada', topic='Hi, I am trying to use Amadeus-GPT (https://github.com/AdaptiveMotorControlLab/AmadeusGPT). I would like to go through this program and clear some of my queries. Thank you!', type='short'),\n",
       " 'sangeetha_110_2024-01-15': ConsultingReport(consultant='sangeetha', content='\\nThe example notebooks did not run even with credits in her account.\\nWe tried the streamlit app and it worked with the sample dataset.\\nBefore trying with her own data, Madhuri explained her experimental setup and what she wants out of it.\\nWhile trying with her own data, she realized that the code does not do what she expected which was to identify regions of interest and produce figures.', date=datetime.datetime(2024, 1, 15, 0, 0), scholar='Madhuri Puvvada', topic='AmadeusGPT', type='hands'),\n",
       " 'sangeetha_111_2024-01-15': ConsultingReport(consultant='sangeetha', content='\\nI shared with Anoushka schedule for the next 3 to 4 club session along with an alternative schedule.\\nWe both agreed that in case one of us is not available, the other can handle the session.\\n\\n', date=datetime.datetime(2024, 1, 15, 0, 0), scholar='Anoushka Jain', topic='Code Explorers Kick-Off Meeting Planning', type='short'),\n",
       " 'sangeetha_112_2024-01-23': ConsultingReport(consultant='sangeetha', content='\\nThis was the final meeting to prepare for the code explorers kick off meeting\\nI shared sciebo ppt with Anoushka\\nWe decided which slides we will talk about\\n', date=datetime.datetime(2024, 1, 23, 0, 0), scholar='Anoushka Jain', topic='Coders club', type='short'),\n",
       " 'sangeetha_113_2024-08-03': ConsultingReport(consultant='sangeetha', content='\\nRukhmani wanted to use predictive modeling to design an learning app but did not know where to start.\\nI suggested that we focus only on learning for three sessions and have another short chat to discuss how we can use those learnings to design the app.\\nI also suggested that we decide what we learn on the day of the hands-on session so she has maximum flexibility.\\n', date=datetime.datetime(2024, 8, 3, 0, 0), scholar='Rukhmani', topic='Talk about a learning project for predictive modeling', type='short'),\n",
       " 'sangeetha_114_2024-03-25': ConsultingReport(consultant='sangeetha', content='\\nWe began by making a list of Rukhmani‚Äôs long term goals which were\\nDesign a learning app similar to anki\\nGet comfortable coding in Python and using github\\nHave a project to show on github\\nStatistical analysis in Python\\nWe further discussed on how she wanted to use statistical analysis for the app. She wanted to make bar plots and show descriptive statistics based grouped by some category.\\nI suggested that we can use Pandas and Seaborn for the whole session and recommended the below structure for the hands-on\\nMake a github repo for the project\\nUse titanic dataset to learn Pandas: Being a well-known dataset we can focus on learning Pandas rather than trying to understand the data\\nGet global statistics and statistics by group using Pandas\\nMake bar-graphs\\nMake a simple fake data that she could expect for the app and do the above operations on them.\\nThrough out the process, we commit regularly and once we are done, we push to github.\\nThe reason for this approach was to make her feel more comfortable coding with me (and also alone without being anxious) by using simple libraries and workflow (make incremental changes based on plan, commit)\\nThroughout the session, we followed defined smaller goals and how we know whether we achieved them. Once we reached that point for every smaller goal, we made a descriptive commit\\nWe accomplished all our session goals.\\n\\n', date=datetime.datetime(2024, 3, 25, 0, 0), scholar='Rukhmani', topic='Predictive modeling', type='hands'),\n",
       " 'sangeetha_115_2024-03-04': ConsultingReport(consultant='sangeetha', content='\\nAnoushka has an issue open on spikeinterface library\\nShe wants to implement three classes suggested by one of the core developers to close the issue\\nAt the same time, she also wants to learn how to do it properly.\\nThis will be a part of a planned publication that has end of May deadline\\nBased on her description of her code, I suggested that we could use two hands-on sessions to identify what classes are needed, implement the most basic but working versions of them, and add/modify as and when required.\\n', date=datetime.datetime(2024, 3, 4, 0, 0), scholar='Anoushka Jain', topic='OOPs', type='short'),\n",
       " 'sangeetha_116_2024-04-04': ConsultingReport(consultant='sangeetha', content='\\nWe started with Rukhmani‚Äôs long term goals and shortlisted building a web app for today‚Äôs session\\nI suggested to use Streamlit as another of her long term goal was to just get comfortable with coding in Python\\nWe took 10 minutes each to read up on Streamlit\\nI gave a small demo on how to use\\nWe then made a script that takes user input for number of cards in a deck and then creates that many cards\\n', date=datetime.datetime(2024, 4, 4, 0, 0), scholar='Rukhmani', topic='Web app building', type='hands'),\n",
       " 'sangeetha_117_2024-08-04': ConsultingReport(consultant='sangeetha', content='\\nWe started with a template code she made with github co-pilot\\nWe noted that starting with the template code was a complex task. Instead, we decided to start with a list of things she wants each of her classes should do\\nWe picked the easiest one without a lot of hidden complexities\\nWe also looked for a test dataset to work on to make sure the refactored code is doing the job as expected\\nWe created one of the classes which is working as expected.\\nAnoushka will work on another class by herself and we have another schedule to finalize code refactoring.\\n', date=datetime.datetime(2024, 8, 4, 0, 0), scholar='Anoushka Jain', topic='Code refactoring - Classes', type='hands'),\n",
       " 'sangeetha_118_2024-09-04': ConsultingReport(consultant='sangeetha', content='\\nAnoushka had worked on the Trainer class by herself with the help of chatGPT but the code was not according to what she would have liked\\nShe wanted the attributes to be in the form of dictionary but the chatGPT code had list of tuples which she found confusing and difficult to understand.\\nWe spent some time to figure out the best way to handle the code but it became clear that we both were confused by what the code was doing.\\nSince we both were confused, we decided to start from higher level (what she would want the user to type for this purpose). We understood that there would be two methods in the class.\\nAnoushka already had pieces for both of these methods which we just copy-pasted to the method.\\nWe also noted that the code has to be refactored in the future to be more maintainable as there were many lines of code in a single method.\\nWe also discussed how to have default arguments/attributes in the class constructor.\\nWe both agreed that Anoushka had learnt enough from this session for her to work by herself. She wanted one more session after this to write few tests for the new classes.\\n', date=datetime.datetime(2024, 9, 4, 0, 0), scholar='Anoushka Jain', topic='Code refactoring - Classes', type='hands'),\n",
       " 'sangeetha_119_2024-04-16': ConsultingReport(consultant='sangeetha', content='\\nAnoushka wrote the Trainer class by herself and demonstrated how it works\\nShe wants to integrate the code with Spike Interface\\nWe went through the requirements of Spike Interface team and identified four things to be done before she can make a pull request\\nFork their repo, create a branch, and run their tests to confirm they are running successfully\\nInstall and use black formatter\\nWrite docstrings to her functions\\nUse sphinx to make documentation of the code\\nWe agreed that she can go through the steps by herself\\nWe will meet for a short session to create pull request\\nWe also noted that she has to write tests for her own code although it is not asked for by the Spike Interface people\\n', date=datetime.datetime(2024, 4, 16, 0, 0), scholar='Anoushka Jain', topic='Feedback on code', type='short'),\n",
       " 'sangeetha_120_2024-04-17': ConsultingReport(consultant='sangeetha', content='\\nMadhuri is using a custom code using psychopy written by a postdoc who quit 2 years ago.\\nShe has a kindle shaped screen with moving stimulus (dots) and she monitors interaction of zebra fish with the dots.\\nThe code creates some visualization which is shown on an external monitor\\nIt worked in Bonn (However)\\nIt worked only on the postdoc account on the desktop\\nIt did not work when they tried to make a separate account for Madhuri. There was a lag in the visualization\\nMadhuri has moved the entire setup to Koln and is facing similar issues.\\nWithout having seen the setup, it is difficult to determine the cause of it but we came up with three possible causes\\nWrong python version in Koln setup\\nWrong psychopy version in Koln setup\\n(Most likely) settings difference of screen refresh rate\\nWe decided to rule out python and psychopy issues by trying out different versions.\\nMadhuri will try it out herself but she also has my hands on booking link in case she needs some help.\\n', date=datetime.datetime(2024, 4, 17, 0, 0), scholar='Madhuri Puvvada', topic='Moving stimuli using Pyschopy', type='short'),\n",
       " 'sangeetha_121_2024-04-18': ConsultingReport(consultant='sangeetha', content='\\nWe had Lukas and Carolin join the meeting. Nick was present in the meeting too.\\nGaia explained the situation wherein they need a file system organization to store and access the data.\\nIn DZNE, some of the data was centralized, most were in personal folders.\\nNow they want to have a system where there is some data which is protected from deletion and modification (raw data) and also store processed data.\\nThere are multiple sources of data which is used by multiple projects and file naming conventions vary from project to project.\\nNick made a suggestion to start with one project, change the file names according to an agreed upon convention, transfer the data to the server. The process is repeated across different projects. Gaia was concerned that this might not be viable as once the file names are set for project 1, they would be hesitant to rename it for project 2. (Since same data is used for both the projects). Gaia would also want to be involved as much as possible with the whole process.\\nEventually, we agreed to\\nGaia and her group will discuss file naming convention across all the projects.\\nThey will book three sessions with Sangeetha. First session will be Sangeetha and one of the group members, second session will be Sangeetha, Nick, and the group member. The last session will include Gaia as well.\\n', date=datetime.datetime(2024, 4, 18, 0, 0), scholar='Gaia Devbiol', topic='Organizing our fileserver structure and primary manage management adn archiving', type='short'),\n",
       " 'sangeetha_122_2024-04-24': ConsultingReport(consultant='sangeetha', content=':\\nMadhuri gave a small demo of her experiment and the issue. We discussed what we saw on the screen where there were some ‚Äòhiccups‚Äô that appeared randomly.\\nThere were few warnings (future warnings, and screen resoultion different to what was expected warning). We also saw that there were around 311 frames dropped. We had two different paths to follow.\\nChange screen resolution and observe the visuals: This was easy to change\\nSee parameters in script that affect time: This was slightly more difficult and we would have to change somethings in the script.\\nWe changed screen resolution to the actual resultion which made stimuli appear smoothly on the screen and also reduced dropped frames to 39. We understood that the lag is because of dropped frames.\\nWe looked through the script where anything related to time in the script. Some were frame second, heart beat seconds. Playing around with them did not change anything.\\nWe then moved into Psychopy parts of the script. Window method in Psychopy takes in many parameters which is responsible for setting up the whole stimuli appearance on the screen. So we worked on that part first.\\nWe tried changing couple of parameters like checkTime=False instead of True but this caused errors. There was another parameter called waitBlanking which is True by default. Typically it is used for controls whether the window should wait for the vertical blanking interval before flipping the buffer. The vertical blanking interval (VBI) is a moment when the display hardware updates the visible screen image. We set it to False since we did not have any fast stimuli. This reduced dropped frames to only two and Madhuri can now carry on with her experiment.\\nWe also discussed how we can further improve the script by using vectorization instead of for loops.\\n', date=datetime.datetime(2024, 4, 24, 0, 0), scholar='Madhuri Puvvada', topic='Trying different versions of python for Pyschopy', type='hands'),\n",
       " 'sangeetha_123_2024-04-25': ConsultingReport(consultant='sangeetha', content='\\nNatalia demonstrated her problem where using vs code to access her files from remote server is not working (does not load at all... No errors either)\\nWe tried to connect from the terminal to see whether the vs code extension was the issue. She could connect without problems.\\nWe then decided to create an SSH tunnel to connect remotely as a work around so she can carry out her urgent data analysis.\\nWe used a combination of stackexchange, chatGPT, and Natalia‚Äôs existing command line to do this. Jupyter notebook opened but needed an access token which we did not know how to get.\\nI worked with Nick after the session (using linode) and figured out what the access token was. It is shown in the terminal where jupyter notebook opens\\nI wrote to Natalia and she said that it worked.\\n', date=datetime.datetime(2024, 4, 25, 0, 0), scholar='Natalia Krasilshchikova', topic='I have an issue from the PC side with connecting to the server in VS code using shh. I can connect from another PC, can connect through the terminal, some time ago I could connect without issues. I run out of ideas of what to check', type='short'),\n",
       " 'sangeetha_124_2024-05-22': ConsultingReport(consultant='sangeetha', content='\\nIvy is a PhD student who is working with calcium imaging data. She has many files with different formats, some python code, and also several jupyter notebooks which she uses as analysis pipeline and also for some data exploration.\\nShe has one project folder and three main folders for model, connectome, and 2-photon analysis. Each of them again has several files which are data, code, or results in the form of figures.\\nShe wants to arrange them in a way which is easier to share with her PI (Gaia Tavonis) and also for herself as she is now working on her paper and finishing up her PhD.\\nI first noticed that she had code files which had v1, v2, etc in their file names. She said that she is using her own way of version controlling (she also has a log file where she manually writes about codes and different tests she has performed). She does not use git for version controlling.\\nI explained to her the benefits of using git and github for this as having multiple code files for different versions can be overwhelming to work with in the future and offered to give a small demo on using git and github. I showed her basic git functions using vs code (without getting into branching).\\nThen we started to work out how to re-organize her files. We used whiteboard in our office for this. Since she is finishing up her PhD, we thought it might be best to come up with a simple structure that is self explanatory without a lot of her input. So we decided that a basic organization of her files into data, code, analysis, and scratch would be ideal.\\n\\n', date=datetime.datetime(2024, 5, 22, 0, 0), scholar='Chi Wai Chan', topic='I am working with connectome analysis, calcium imaging data and modeling, I am looking forward to improve the way I organize my data and files!', type='hands'),\n",
       " 'sangeetha_125_2024-10-06': ConsultingReport(consultant='sangeetha', content=':\\nNicole is a bachelors student who will be working with a PhD student to collect and analyze data\\nShe came to the session using the link sent around by Gaia to her group which was a hands-on link and not a short chat link\\nShe thought that iBOTS would lead the whole thing as she was under the assumption that Gaia had discussed about the process with us.\\nI spoke with her more about what was discussed with Gaia which was that I will handle data management at individual level and Nick will handle lab level changes.\\nWe tried out eLab journal and Nicole suggested that she wants to book a short chat instead of hands-on where we can discuss what she wants to do. For that she wanted to book on a different date to have enough preparation time.\\nI sent her a link to my short chat\\n', date=datetime.datetime(2024, 10, 6, 0, 0), scholar='Nicole Wedeschkin', topic='I am a student working in the Institute of Developmental Biology (Tavosanis AG)', type='hands'),\n",
       " 'sangeetha_126_2024-06-13': ConsultingReport(consultant='sangeetha', content=':\\nMatlab is installed on a server by another member of lab\\nEach of them is supposed to have a license to work with Matlab but for Rukhmani it was not working\\nComparing existing (working) licenses of her lab members with her license showed that there is a difference between host id (identifyer of the host)\\nWe added a new licence on her matlab account with her username and correct host id which she then copied to her folder on the server. With this license, the code works\\nAnother minor annoyance that she faced was that she had to type in her password to remote server for every minor file navigation. She showed me a series of steps given by one of the PIs that she had followed but could not get it to work.\\nThe steps can boil down to two steps, one is generating key on client machine and then copying the authorize_key to server.\\nWe discovered that the keygen was also generated on server. Correcting it solved her issue\\n', date=datetime.datetime(2024, 6, 13, 0, 0), scholar='Rukhmani', topic='License issue with Matlab', type='hands'),\n",
       " 'sangeetha_127_2024-06-27': ConsultingReport(consultant='sangeetha', content=':\\nWe spoke a bit about what iBOTS does and our services\\nJonathan does not have a lot of data but he wants to learn about management before starting his PhD formally\\nWe also spoke about code management and since he did not have a lot of experience with Python and jupyter notebook, we decided to do a learning project on how to manage code\\nJonathan will book three sessions (two to start off with) to do the same.\\n', date=datetime.datetime(2024, 6, 27, 0, 0), scholar='Jonathan Mark Smart', topic=\"Hi, I'm a part of Gaia Tavosanis lab and I will be starting a PhD in September. I believe you've talked with other members of the lab I would love to have a chat!\", type='short'),\n",
       " 'sangeetha_128_2024-04-07': ConsultingReport(consultant='sangeetha', content='Rukhmani is leaving next week and wanted some help with her analysis code and resolving merge conflicts on github. We started with merge conflicts and came up with two solutions.\\nSolve them one by one\\nFrequently pull so that you are always working on latest file\\nWe also spoke about how to go to a previous commit in the code.\\nHer analysis code was based on her supervisor Tobias Rose‚Äôs code. She wanted help to understand what was happening. We also explored data joints as the code used that mostly and also a little SQL.\\n', date=datetime.datetime(2024, 4, 7, 0, 0), scholar='Rukhmani Narayanamurthi', topic='', type='hands'),\n",
       " 'sangeetha_129_2024-04-07': ConsultingReport(consultant='sangeetha', content='Moritz is a regular and an active participant in the Code Explorers club. We wanted his ideas to make the club attractive to more people. His suggestions were the following\\nUse the retreat to discuss needs and wants of researchers.\\nWe can have a ‚ÄòMeet and Build‚Äô session where we pick a topic and work together during the session to build something.\\n', date=datetime.datetime(2024, 4, 7, 0, 0), scholar='Moritz Haustein', topic='discussing code explorers club future', type='short'),\n",
       " 'sangeetha_130_2024-05-07': ConsultingReport(consultant='sangeetha', content='Natalia did not know how to pull from original repo into her forked repo while also retaining her changes. We worked together on how to pull from original repo, solve merge conflicts, pushing to forked repo. We also had a conversation on how often to commit, pull from remote. All in all, a good session. Her issue was more specific and we were able to work on it during the short chat (>1 hour).\\n', date=datetime.datetime(2024, 5, 7, 0, 0), scholar='Natalia Krasilshchikova', topic='Could you please help me to understand git better?', type='short'),\n",
       " 'sangeetha_131_2024-07-15': ConsultingReport(consultant='sangeetha', content='Rukhmani has a code from her supervisor that she uses for data analysis. The code pulls the data from PyRat (using datajoint) and the code did not find data for her subject (rat). According to the error message, her rat was sacrificed. She got similar message when the rat was alive. We wanted to eliminate different causes for this. First, we checked if connection to PyRat was successful. We checked response and it was 200. Then we checked if she could see any table in the response (she could). We noted down one of them for testing (lets call it subject_a). We also checked the code and it searched for both live and sacrificed subjects. We tested if subject_a could be retrieved with the same code and we could. Then we tested another subject of Rukhmani which could also be retrieved. We realized that probably her current subject was not properly uploaded. Rukhmani will look into it before our next session.\\n', date=datetime.datetime(2024, 7, 15, 0, 0), scholar='Rukhmani Narayanamurthy', topic='', type='hands'),\n",
       " 'sangeetha_132_2024-07-15': ConsultingReport(consultant='sangeetha', content='Jana wants to write a general script in matlab for video and audio synchronization. We decided to have two in-person hands-on sessions where we will work on a simple example and then use it to make a general script.\\n', date=datetime.datetime(2024, 7, 15, 0, 0), scholar='Jana Sleeboom', topic='Dear iBots team, my idea is to do video and audio recording (ultrasonic range) simultaneously. I am doing an interaction behavior task, recording video and audio for 30 min. Right now, start and stop of the recordings is not synchronized. My idea is to use Matlab for the recording and synchronization. Can you help me with that?', type='short'),\n",
       " 'sangeetha_133_2024-07-19': ConsultingReport(consultant='sangeetha', content='Rukhmani wanted me to be a coding assistant for her analysis project that she is working on. We used the session to understand the data schema, how to access data from data joints, and then convert angular velocity information from her experiment to linear velocity.\\n', date=datetime.datetime(2024, 7, 19, 0, 0), scholar='Rukhmani Narayanamurthy', topic='', type='hands'),\n",
       " 'sangeetha_134_2024-07-22': ConsultingReport(consultant='sangeetha', content='We used the session to learn more about data joints, some SQL, and then using that to add trial dimension to position and licks (behaviour)..\\n', date=datetime.datetime(2024, 7, 22, 0, 0), scholar='Rukhmani Narayanamurthy', topic='', type='hands'),\n",
       " 'sangeetha_135_2024-07-23': ConsultingReport(consultant='sangeetha', content='We made some few diagnostic plots to assess whether our split into trials based on trial start times were correct. Rukhmani then remembered that another database already has trial start times. Therefore We worked on making a simple loop structure to automate the process. We created a dummy dataset (simple numpy arrays for learning and testing) for our little learning project. In the upcoming sessions, we will apply our learning to her actual dataset.\\n\\n\\n', date=datetime.datetime(2024, 7, 23, 0, 0), scholar='Rukhmani Narayanamurthy', topic='', type='hands')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load().consulting_reports"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibots-site",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
